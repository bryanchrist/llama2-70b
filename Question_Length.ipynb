{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48d4641-7b11-4bcd-9fbd-958ae4fea7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U torch==2.0.1 bitsandbytes==0.40.2\n",
    "%pip install -q -U transformers==4.35.2 peft==0.4.0 accelerate==0.21.0\n",
    "%pip install -q -U datasets py7zr einops tensorboardX\n",
    "!pip install evaluate\n",
    "# Add installed cuda runtime to path for bitsandbytes\n",
    "import os\n",
    "import nvidia\n",
    "\n",
    "cuda_install_dir = '/'.join(nvidia.__file__.split('/')[:-1]) + '/cuda_runtime/lib/'\n",
    "os.environ['LD_LIBRARY_PATH'] =  cuda_install_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25fac1e2-0e86-48ae-b949-9be69f9b912a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Path to your env.txt file\n",
    "env_file_path = 'data/env.txt'\n",
    "\n",
    "# Read and set environment variables\n",
    "with open(env_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        key, value = line.strip().split('=')\n",
    "        os.environ[key] = value\n",
    "token = os.environ['huggingface_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a89425-0033-464c-8118-979e331c89f2",
   "metadata": {},
   "source": [
    "## Check Length of MATHWELL Training Data and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9879775-8fe8-4e65-8016-cf5e75a306a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mathwell_annotations_final.csv')\n",
    "model_path = \"meta-llama/Llama-2-70b-hf\"   # Specify the path to the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1bf4577-e0f2-4078-a620-6bcd601b94bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average question length in tokens: 191.32467532467533\n"
     ]
    }
   ],
   "source": [
    "question_lengths = 0\n",
    "for i in range(0, len(df)):\n",
    "    output = df.iloc[i]['output']\n",
    "    try: \n",
    "        inputs = tokenizer.encode(output, return_tensors=\"pt\")\n",
    "    except:\n",
    "        pass\n",
    "    length = inputs.shape[1]\n",
    "    question_lengths+=length\n",
    "print(f\"Average question length in tokens: {question_lengths/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3951856-3641-4d03-bdd7-388109b8389f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average input length in tokens: 2045.103\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/mathwell.csv')\n",
    "import random\n",
    "topics = ['Superman', \"Batman\", \"Wonder Woman\", \"Barbie\", \"Power Rangers\", \"basketball\", \"soccer\", \"football\", \"volleyball\", 'field hockey',\\\n",
    "'Fortnite', 'Spiderman', \"Iron Man\", \"Captain America\", \"Captain Marvel\", \"Thor, the God of Thunder\", \"Ninja Turtles\", \"Black Panther\", \"Taylor Swift\", \"swimming\",\\\n",
    "\"Pokémon\", \"Super Mario\", \"Naruto\", \"unicorns\", \"Hello Kitty\", \"Minecraft\", \"lacrosse\", \"cheer leading\", \"LeBron James\", \"Steph Curry\", \"Patrick Mahomes\",\\\n",
    "\"Serena Williams\", \"dogs\", \"cats\", \"dinosaurs\", \"Harry Potter\", \"cars\", \"planes\", \"trains\", \"pizza\", \"cookies\", \"ice cream\", 'candy']\n",
    "question_lengths = 0\n",
    "for i in range(0,1000):\n",
    "    topic = random.choice(topics)\n",
    "    final_prompt = f\"Write a grade school math word problem about {topic} and Python function with a commented out step-by-step solution to solve the word problem.\"\n",
    "    prompt = \"Write a grade school math word problem and Python function with a commented out step-by-step solution to solve the word problem.\"\n",
    "    questions = []\n",
    "    for i in range(0, 8):\n",
    "        question = df['output'].iloc[random.randint(0,len(df)-1)]\n",
    "        questions.append(question)\n",
    "    formatted_prompt = []\n",
    "    for i in range(0,8):\n",
    "        formatted_prompt.append((f\"Below is an instruction that describes a task. \"\n",
    "                f\"Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{prompt}\\n\\n### Response: {questions[i]}\"))\n",
    "    formatted_prompt.append(f\"Below is an instruction that describes a task. \"\n",
    "                f\"Write a response that appropriately completes the request.\\n\\n\"\n",
    "                f\"### Instruction:\\n{final_prompt}\\n\\n### Response: \")\n",
    "    formatted_prompt = \"\\n\".join(formatted_prompt)\n",
    "    inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\")\n",
    "    length = inputs.shape[1]\n",
    "    question_lengths+=length\n",
    "print(f\"Average input length in tokens: {question_lengths/1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83aa2fd6-678b-406b-9b19-6b9d864fac54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_length(df):\n",
    "    question_lengths = []\n",
    "    for i in range(0, len(df)):\n",
    "        output = df.iloc[i]['text']\n",
    "        try: \n",
    "            inputs = tokenizer.encode(output, return_tensors=\"pt\")\n",
    "        except:\n",
    "            pass\n",
    "        length = inputs.shape[1]\n",
    "        question_lengths.append(length)\n",
    "    return question_lengths\n",
    "def check_mathwell(df):\n",
    "    question_lengths = []\n",
    "    for i in range(0, len(df)):\n",
    "        output = df.iloc[i]['question']\n",
    "        try: \n",
    "            inputs = tokenizer.encode(output, return_tensors=\"pt\")\n",
    "        except:\n",
    "            pass\n",
    "        length = inputs.shape[1]\n",
    "        question_lengths.append(length)\n",
    "    return question_lengths\n",
    "def check_length_good(df):\n",
    "    question_lengths = []\n",
    "    for i in range(0, len(df)):\n",
    "        output = df.iloc[i]['question']\n",
    "        try: \n",
    "            inputs = tokenizer.encode(output, return_tensors=\"pt\")\n",
    "        except:\n",
    "            pass\n",
    "        length = inputs.shape[1]\n",
    "        question_lengths.append(length)\n",
    "    return question_lengths\n",
    "def check_gsm8k(df):\n",
    "    question_lengths = []\n",
    "    for i in range(0, len(df)):\n",
    "        output = str(df.iloc[i]['instruction'])\n",
    "        try: \n",
    "            inputs = tokenizer.encode(output, return_tensors=\"pt\")\n",
    "        except:\n",
    "            pass\n",
    "        length = inputs.shape[1]\n",
    "        if length>2:\n",
    "            question_lengths.append(length)\n",
    "    return question_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b7614-856b-4dbc-a54f-fa48575458b0",
   "metadata": {},
   "source": [
    "## Check Average Length of GSM8K Training Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de3ef76-453e-4563-b99c-c5ac3c517471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 65.66239462682475 Standard Deviation: 23.70797156147507\n"
     ]
    }
   ],
   "source": [
    "gsm8k = pd.read_csv('data/gsm8k_questions.csv')\n",
    "gsm8k = check_gsm8k(gsm8k)\n",
    "print(f'Average overall question length in tokens: {np.mean(gsm8k)} Standard Deviation: {np.std(gsm8k)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c2db5-4456-4c02-9937-890759839bc0",
   "metadata": {},
   "source": [
    "## Check Length of MATHWELL Training Data, Questions Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c48571-18d9-40af-8eae-f7aff1ea52b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 58.95063145809414 Standard Deviation: 16.551501822337883\n"
     ]
    }
   ],
   "source": [
    "mathwell_an = pd.read_csv('data/mathwell_annotations_final.csv')\n",
    "mathwell_an_len = check_mathwell(mathwell_an)\n",
    "print(f'Average overall question length in tokens: {np.mean(mathwell_an_len)} Standard Deviation: {np.std(mathwell_an_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20c87b2-15df-4c23-b2b3-b12527ffbba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average good question length in tokens: 57.259312320916905 Standard Deviation: 15.729965098829148\n"
     ]
    }
   ],
   "source": [
    "mathwell_train = mathwell_an[mathwell_an['good']==1]\n",
    "mathwell_train = check_length_good(mathwell_train)\n",
    "print(f'Average good question length in tokens: {np.mean(mathwell_train)} Standard Deviation: {np.std(mathwell_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c70c7-ea00-4ef5-ad3a-a39ceaf29a88",
   "metadata": {},
   "source": [
    "## Check Length of MATHWELL Final Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a59786-ea53-4d53-ad64-18abdd31b1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 55.24 Standard Deviation: 13.84826342903687\n"
     ]
    }
   ],
   "source": [
    "mathwell_all = pd.read_csv('data/mathwell_solvability.csv')\n",
    "mathwell = check_length(mathwell_all)\n",
    "print(f'Average overall question length in tokens: {np.mean(mathwell)} Standard Deviation: {np.std(mathwell)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd5ad360-d386-4271-9c56-8caf87e45bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average good question length in tokens: 54.537234042553195 Standard Deviation: 13.804628302212464\n"
     ]
    }
   ],
   "source": [
    "mathwell_good = pd.read_csv('data/mathwell_good.csv')\n",
    "mathwell_good = check_length_good(mathwell_good)\n",
    "print(f'Average good question length in tokens: {np.mean(mathwell_good)} Standard Deviation: {np.std(mathwell_good)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d678226-9b70-4f9f-a78a-35fadbc57b77",
   "metadata": {},
   "source": [
    "## Check Length of Llama Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a67b78d-a274-4132-bd33-58f186677544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 53.08 Standard Deviation: 15.637442246096388\n"
     ]
    }
   ],
   "source": [
    "llama_all = pd.read_csv('data/llama_solvability.csv')\n",
    "llama = check_length(llama_all)\n",
    "print(f'Average overall question length in tokens: {np.mean(llama)} Standard Deviation: {np.std(llama)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ebb7fe-cc37-402e-99ee-f2329553f4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average good question length in tokens: 51.547770700636946 Standard Deviation: 14.40870484412119\n"
     ]
    }
   ],
   "source": [
    "llama_good = pd.read_csv('data/llama_good.csv')\n",
    "llama_good = check_length_good(llama_good)\n",
    "print(f'Average good question length in tokens: {np.mean(llama_good)} Standard Deviation: {np.std(llama_good)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442efe92-e948-4fc2-9045-61a48500c713",
   "metadata": {},
   "source": [
    "## Check Length of LLEMA Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d373b9ab-bd6f-4225-a35a-5d07fc098a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 56.516 Standard Deviation: 22.56549897520549\n"
     ]
    }
   ],
   "source": [
    "llema_all = pd.read_csv('data/llema_solvability.csv')\n",
    "llema = check_length(llema_all)\n",
    "print(f'Average overall question length in tokens: {np.mean(llema)} Standard Deviation: {np.std(llema)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f065b9d3-842a-4881-b831-ac5f9289d909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average good question length in tokens: 51.1219512195122 Standard Deviation: 17.264364993586263\n"
     ]
    }
   ],
   "source": [
    "llema_good = pd.read_csv('data/llema_good.csv')\n",
    "llema_good = check_length_good(llema_good)\n",
    "print(f'Average good question length in tokens: {np.mean(llema_good)} Standard Deviation: {np.std(llema_good)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13a3c6-bf8d-4f4d-b15e-16c7f9ce8821",
   "metadata": {},
   "source": [
    "## Check Length of MAmmoTH Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd2353c6-131d-46c6-b101-e24e22cf56a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 46.056 Standard Deviation: 17.86809626121373\n"
     ]
    }
   ],
   "source": [
    "mammoth_all = pd.read_csv('data/mammoth_solvability.csv')\n",
    "mammoth = check_length(mammoth_all)\n",
    "print(f'Average overall question length in tokens: {np.mean(mammoth)} Standard Deviation: {np.std(mammoth)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16366db8-01a6-4398-a6f2-cf67a90feb92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average good question length in tokens: 43.957142857142856 Standard Deviation: 13.371008845671309\n"
     ]
    }
   ],
   "source": [
    "mammoth_good = pd.read_csv('data/mammoth_good.csv')\n",
    "mammoth_good = check_length_good(mammoth_good)\n",
    "print(f'Average good question length in tokens: {np.mean(mammoth_good)} Standard Deviation: {np.std(mammoth_good)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707d69a-d136-45a6-ab83-1d993a92281a",
   "metadata": {},
   "source": [
    "## Check Length of NumGLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "298bd531-2d28-4cce-910c-eeac0529ca84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 145.77979749661165 Standard Deviation: 136.64416090041578\n"
     ]
    }
   ],
   "source": [
    "numglue = pd.read_csv('data/numglue_questions.csv')\n",
    "numglue_len = check_gsm8k(numglue)\n",
    "print(f'Average overall question length in tokens: {np.mean(numglue_len)} Standard Deviation: {np.std(numglue_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9100cc5-e32e-4b9d-aa2a-fa5d084eb131",
   "metadata": {},
   "source": [
    "## Check Length of ASDIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80f1c346-ebb5-415a-8d0c-9fab8058bfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 45.06898047722343 Standard Deviation: 15.753717766689356\n"
     ]
    }
   ],
   "source": [
    "asdiv = pd.read_csv('data/ASDiv_clean.csv')\n",
    "asdiv_len = check_length_good(asdiv)\n",
    "print(f'Average overall question length in tokens: {np.mean(asdiv_len)} Standard Deviation: {np.std(asdiv_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d02c3-a95b-43c0-8530-2fa9233df05a",
   "metadata": {},
   "source": [
    "## Check Length of SVAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a77031f8-b989-4abb-b14f-f4d2673764bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 47.268 Standard Deviation: 11.699067313251941\n"
     ]
    }
   ],
   "source": [
    "svamp = pd.read_json('data/SVAMP.json')\n",
    "svamp['question'] = svamp['Body'] + \" \" + svamp['Question']\n",
    "svamp_len = check_length_good(svamp)\n",
    "print(f'Average overall question length in tokens: {np.mean(svamp_len)} Standard Deviation: {np.std(svamp_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5d00b-5003-4213-9314-dc4d0a06fc43",
   "metadata": {},
   "source": [
    "## Check Length of GSM-Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b32df27-ebb9-44e7-a909-f504b965d9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average overall question length in tokens: 72.9294920394238 Standard Deviation: 25.636173190635287\n"
     ]
    }
   ],
   "source": [
    "gsm_hard = pd.read_json('data/gsmhard.json')\n",
    "gsm_hard_len = check_length_good(gsm_hard)\n",
    "print(f'Average overall question length in tokens: {np.mean(gsm_hard_len)} Standard Deviation: {np.std(gsm_hard_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7ad9a-6d74-4819-8aaf-ad4fb03882ba",
   "metadata": {},
   "source": [
    "## Tests for Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2724bf90-a085-4ea9-9ecb-de1491af4f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 0.7604991428423419\n",
      "P-value: 0.44731618802821826\n"
     ]
    }
   ],
   "source": [
    "# Perform an independent two-sample t-test on solvability\n",
    "t_statistic, p_value = stats.ttest_ind(llema, mathwell)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "062e9375-f6aa-4ab2-acd5-548dbe7f2b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 14.558138817920046\n",
      "P-value: 1.0248750555174296e-47\n"
     ]
    }
   ],
   "source": [
    "# Perform an independent two-sample t-test on solvability\n",
    "t_statistic, p_value = stats.ttest_ind(gsm8k, mathwell_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13db5de5-d15e-4b56-bee5-b0aac58a56d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 0.7604991428423419\n",
      "P-value: 0.44731618802821826\n"
     ]
    }
   ],
   "source": [
    "# Perform an independent two-sample t-test on solvability\n",
    "t_statistic, p_value = stats.ttest_ind(llema, mathwell)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6a0182b-f021-4e13-a310-3d77a89afaee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -1.957775025575982\n",
      "P-value: 0.05106687191095604\n"
     ]
    }
   ],
   "source": [
    "# Perform an independent two-sample t-test on solvability\n",
    "t_statistic, p_value = stats.ttest_ind(llama_good, mathwell_good)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12340b8-960b-445e-a0a3-f14199532b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
