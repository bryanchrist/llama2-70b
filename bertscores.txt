Average GSM8K overall BERTScore: Precision: 0.8471522494183646, Recall: 0.847014728585879, F1: 0.8469969493415621
Average MATHWELL Train overall BERTScore: Precision: 0.8502784208615621, Recall: 0.8510564319239723, F1: 0.8505710665570365
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8385263025893105, Recall: 0.8477788354317347, F1: 0.8430502842320337
Average MATHWELL overall BERTScore: Precision: 0.8529472214460373, Recall: 0.8554133501708507, F1: 0.8540826505661011
Average MATHWELL MaC overall BERTScore: Precision: 0.8549211949944496, Recall: 0.8580031839311123, F1: 0.8563688972353936
Average MATHWELL MaC/MATHWELL Train overall BERTScore: Precision: 0.8534447733693653, Recall: 0.8526850340949165, F1: 0.852974559044838
Average MATHWELL MaC/MATHWELL all generations BERTScore: Precision: 0.855183902835846, Recall: 0.856173060186704, F1: 0.8555822678248087
Average llama overall BERTScore: Precision: 0.8542998584210872, Recall: 0.8540104838848114, F1: 0.8540191255152225
Average llama MaC overall BERTScore: Precision: 0.8576101831972599, Recall: 0.8567372686326504, F1: 0.8570596746146679
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8572957245720757, Recall: 0.8557121141566171, F1: 0.8563816287702984
Average llema overall BERTScore: Precision: 0.8420517384290696, Recall: 0.8427451902866363, F1: 0.842240979129076
Average GSM8K overall BERTScore: Precision: 0.8469565209642053, Recall: 0.8461447440534831, F1: 0.8464618147432804
Average MATHWELL Train overall BERTScore: Precision: 0.8513518596410752, Recall: 0.8517021996945143, F1: 0.8514354492008686
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8403197825178504, Recall: 0.8461471973508596, F1: 0.8431420533314348
Average GSM8K overall BERTScore: Precision: 0.8469565209642053, Recall: 0.8461447440534831, F1: 0.8464618147432804
Average MATHWELL Train overall BERTScore: Precision: 0.8513518596410752, Recall: 0.8517021996945143, F1: 0.8514354492008686
Average MATHWELL Annotated overall BERTScore: Precision: 0.8443969956278801, Recall: 0.8440688721239566, F1: 0.8441400542721152
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8421765577539801, Recall: 0.8481686924293638, F1: 0.8450867074072361
Average MATHWELL Annotated/GSM8K overall BERTScore: Precision: 0.8405035879939795, Recall: 0.8459433189734816, F1: 0.8431292686328292
Average MATHWELL overall BERTScore: Precision: 0.8542634417189492, Recall: 0.8559481521023644, F1: 0.855009127079116
Average MATHWELL MaC overall BERTScore: Precision: 0.8559311995638741, Recall: 0.8570790422704485, F1: 0.8564082360612022
Average MATHWELL MaC/MATHWELL Train overall BERTScore: Precision: 0.8547390955940206, Recall: 0.8522132346271835, F1: 0.8533777722002978
Average MATHWELL MaC/MATHWELL all generations BERTScore: Precision: 0.8561087469566375, Recall: 0.856297265546436, F1: 0.856106817229314
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8466331116807587, Recall: 0.8413413157551847, F1: 0.8438908415684041
Average llama overall BERTScore: Precision: 0.8542358335256577, Recall: 0.854047078095542, F1: 0.8540021144072215
Average llama MaC overall BERTScore: Precision: 0.8577916333807839, Recall: 0.8575055886586507, F1: 0.8575399140675862
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8560642276258226, Recall: 0.8541825247703084, F1: 0.8549976828485537
Average llama MaC/GSM8K BERTScore: Precision: 0.8492369993040516, Recall: 0.8401760799717751, F1: 0.8445923418546938
Average llema overall BERTScore: Precision: 0.8426897490978241, Recall: 0.8431476764069663, F1: 0.8427685074647268
Average llema MaC overall BERTScore: Precision: 0.8533067850397145, Recall: 0.8533067850397145, F1: 0.8532173474724274
Average llema all generations/llema MaC overall BERTScore: Precision: 0.8484562948564204, Recall: 0.8444674874369691, F1: 0.8463331819380202
Average llema MaC/GSM8K BERTScore: Precision: 0.8485364828095203, Recall: 0.840709045812851, F1: 0.8445309536704203
Average mammoth overall BERTScore: Precision: 0.858730476000574, Recall: 0.8604984874937269, F1: 0.8594948509163327
Average mammoth MaC overall BERTScore: Precision: 0.8638068036066026, Recall: 0.8638068036066026, F1: 0.8637128331162491
Average mammoth all generations/mammoth MaC overall BERTScore: Precision: 0.8626276576348714, Recall: 0.8606136351291622, F1: 0.8615091008522681
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8551680223005158, Recall: 0.8418426455961806, F1: 0.8483671792617866
Average numglue overall BERTScore: Precision: 0.8073339698329568, Recall: 0.806794936567545, F1: 0.8064773639425635
Average MATHWELL Train overall BERTScore: Precision: 0.8519595927640796, Recall: 0.8527416401341558, F1: 0.8522530140385032
Average MATHWELL Annotated overall BERTScore: Precision: 0.8447176705524325, Recall: 0.8463437369793654, F1: 0.8454368771448731
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8412310455352068, Recall: 0.8474164121598006, F1: 0.8442316555917263
Average MATHWELL Annotated/GSM8K overall BERTScore: Precision: 0.8398681085556745, Recall: 0.8429979336321354, F1: 0.8413339368775486
Average MATHWELL MaC/MATHWELL Train overall BERTScore: Precision: 0.8519475573761032, Recall: 0.852475043876057, F1: 0.8521112772743119
Average MATHWELL Annotated/MATHWELL Train BERTScore: Precision: 0.8516618399739265, Recall: 0.8520580552592874, F1: 0.8517635877341032
Average asdiv overall BERTScore: Precision: 0.8612890245139598, Recall: 0.8697439480915665, F1: 0.8654352985024453
Average svamp overall BERTScore: Precision: 0.8604789712235331, Recall: 0.860896236602962, F1: 0.8606245523452759
Average gsmhard overall BERTScore: Precision: 0.8373232307314873, Recall: 0.8407965356945991, F1: 0.8389891711726785


 ### New Results ### 

Average GSM8K overall BERTScore: Precision: 0.8463350078031421, Recall: 0.8457823706323901, F1: 0.8459777488627368
Average MATHWELL Train overall BERTScore: Precision: 0.8517336996032132, Recall: 0.8521391431990597, F1: 0.8518413429018524
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8406809953004122, Recall: 0.8465386409797602, F1: 0.8435248461650477
Average MATHWELL overall BERTScore: Precision: 0.855087990603447, Recall: 0.855087990603447, F1: 0.854990834227562
Average MATHWELL MaC overall BERTScore: Precision: 0.8568606327202267, Recall: 0.8568606327202267, F1: 0.856763548810067
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8462206601922182, Recall: 0.8403072216705227, F1: 0.843168612526241
Average llama overall BERTScore: Precision: 0.8545193456668854, Recall: 0.8545193456611633, F1: 0.8543819382953644
Average llama MaC overall BERTScore: Precision: 0.8574004992422523, Recall: 0.8574004992083984, F1: 0.8572935738656975
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8566114011737191, Recall: 0.8548038839974981, F1: 0.8555844218837227
Average llama MaC/GSM8K BERTScore: Precision: 0.8491229394255424, Recall: 0.839475265346515, F1: 0.8441834707573974
Average llema overall BERTScore: Precision: 0.8431368972091675, Recall: 0.8431368972063065, F1: 0.8429839361667633
Average llema MaC overall BERTScore: Precision: 0.8533067850397145, Recall: 0.8533067850397145, F1: 0.8532173474724274
Average llema all generations/llema MaC overall BERTScore: Precision: 0.8483775781538428, Recall: 0.8445171670041434, F1: 0.8463217939051186
Average llema MaC/GSM8K BERTScore: Precision: 0.847917275736487, Recall: 0.8397503868011924, F1: 0.8437362130386074
Average mammoth overall BERTScore: Precision: 0.8595782812166214, Recall: 0.8595782812080384, F1: 0.8594555507640839
Average mammoth MaC overall BERTScore: Precision: 0.8638068036066026, Recall: 0.8638068036066026, F1: 0.8637128331162491
Average mammoth all generations/mammoth MaC overall BERTScore: Precision: 0.8622202548282487, Recall: 0.8605734646218164, F1: 0.8612879826971462
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8551877734746252, Recall: 0.8410826649091073, F1: 0.8479968668577217
Average numglue overall BERTScore: Precision: 0.8100303893451889, Recall: 0.8091517146598962, F1: 0.8090287285524937
Average asdiv overall BERTScore: Precision: 0.8613161743977004, Recall: 0.8594202580746677, F1: 0.8602772684145304
Average svamp overall BERTScore: Precision: 0.860844921282596, Recall: 0.8606483964582284, F1: 0.8606788149462806
Average gsmhard overall BERTScore: Precision: 0.8385188762464457, Recall: 0.8400485499901904, F1: 0.8392074754829209


 ### New Results ### 

Average GSM8K overall BERTScore: Precision: 0.8463852537822393, Recall: 0.8459586809621917, F1: 0.8460895142622292
Average MATHWELL Train overall BERTScore: Precision: 0.8519051793324864, Recall: 0.8522180024368895, F1: 0.8519682793207467
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8409931592690448, Recall: 0.8469688523673763, F1: 0.843884959167449
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8463672593008753, Recall: 0.8409728266864169, F1: 0.8435766987185529
Average llama MaC/GSM8K BERTScore: Precision: 0.849233423777067, Recall: 0.8402526020149517, F1: 0.8446296806190551
Average llema MaC/GSM8K BERTScore: Precision: 0.8478519863399063, Recall: 0.8405930674960458, F1: 0.8441317249955685
Average mammoth MaC/GSM8K BERTScore: Precision: 0.855461958841199, Recall: 0.841395986013824, F1: 0.8482834465400804


 ### New Results ### 

Average GSM8K overall BERTScore: Precision: 0.8464819423764646, Recall: 0.8462174079846293, F1: 0.8462691373185665
Average MATHWELL Train overall BERTScore: Precision: 0.8520135447654128, Recall: 0.8521414796256274, F1: 0.8519829887767881
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.84103466371952, Recall: 0.8471033323392272, F1: 0.8439715274021774
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8462772779873832, Recall: 0.8400845613587771, F1: 0.8430850352602987
Average llama MaC/GSM8K BERTScore: Precision: 0.8493552371025043, Recall: 0.8406457645356157, F1: 0.8448927224557915
Average llema MaC/GSM8K BERTScore: Precision: 0.8475205120776081, Recall: 0.8397740597254597, F1: 0.8435500626990688
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8553276214975171, Recall: 0.8417663921752819, F1: 0.8484089410937062
Average numglue overall BERTScore: Precision: 0.8102336452487559, Recall: 0.8111730814018696, F1: 0.8101489151146114
Average asdiv overall BERTScore: Precision: 0.8546161655558646, Recall: 0.8556066909613609, F1: 0.8550272598860711
Average svamp overall BERTScore: Precision: 0.8608132272217107, Recall: 0.8608140687881318, F1: 0.8607456065121613
Average gsmhard overall BERTScore: Precision: 0.8396517699418534, Recall: 0.8396507306969734, F1: 0.8395743991713114


 ### New Results ### 

Average SGSM Unannotated overall BERTScore: Precision: 0.8492237999137193, Recall: 0.849300030716002, F1: 0.849156842663914
Average SGSM Unannotated/GSM8K overall BERTScore: Precision: 0.8391571048041732, Recall: 0.8414310363559425, F1: 0.8402079176513404
Average SGSM Unannotated/SGSM Train overall BERTScore: Precision: 0.8510189899611325, Recall: 0.8468993789018094, F1: 0.8488576490049213
Average SGSM overall BERTScore: Precision: 0.8509501949535012, Recall: 0.8467891506591291, F1: 0.8487658106383831


 ### New Results ### 

Average SGSM Unannotated overall BERTScore: Precision: 0.8492237998831272, Recall: 0.849300030724585, F1: 0.8491568426532596
Average SGSM Unannotated/GSM8K overall BERTScore: Precision: 0.8387605154637694, Recall: 0.8409564510956854, F1: 0.8397695180227309
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8453030654617155, Recall: 0.8401764316015333, F1: 0.8426482852887414
Average llama MaC/GSM8K BERTScore: Precision: 0.8471299175050727, Recall: 0.8406530348408807, F1: 0.8437780696569421
Average llema MaC/GSM8K BERTScore: Precision: 0.8429741771045035, Recall: 0.8388507073170267, F1: 0.8407949149344904
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8529244463856694, Recall: 0.8410402562530521, F1: 0.8468436685767973
Average MATHWELL MaC overall BERTScore: Precision: 0.8566554269740186, Recall: 0.8566552700494674, F1: 0.8565590759286829
Average MATHWELL MaC/MATHWELL all generations BERTScore: Precision: 0.8555230824050878, Recall: 0.8559281541714872, F1: 0.8556287930977111
Average llama MaC overall BERTScore: Precision: 0.8570214612456748, Recall: 0.8569885549315153, F1: 0.8568967617339063
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8563338449885768, Recall: 0.854728438039761, F1: 0.8554074860343169
Average llema MaC overall BERTScore: Precision: 0.851078468747437, Recall: 0.8506449111116429, F1: 0.8507528905135889
Average llema all generations/llema MaC overall BERTScore: Precision: 0.846706145164696, Recall: 0.8441282277123938, F1: 0.8452851311678345
Average mammoth MaC overall BERTScore: Precision: 0.8633810276652027, Recall: 0.8633676038396538, F1: 0.8632773610164121
Average mammoth all generations/mammoth MaC overall BERTScore: Precision: 0.8618808066411892, Recall: 0.8605010092211383, F1: 0.8610810652755148


 ### New Results ### 

Average SGSM Unannotated overall BERTScore: Precision: 0.8492821180198789, Recall: 0.849403464003995, F1: 0.8492388358585834


 ### New Results ### 

Average SGSM Unannotated overall BERTScore: Precision: 0.8489640324592889, Recall: 0.8494992369530946, F1: 0.8491320841158628
Average SGSM Unannotated/GSM8K overall BERTScore: Precision: 0.8383880720486044, Recall: 0.8402668056953847, F1: 0.8392409560542554
Average SGSM Unannotated/SGSM Train overall BERTScore: Precision: 0.8508869737810194, Recall: 0.8462588197712749, F1: 0.8484688529315293
Average SGSM overall BERTScore: Precision: 0.8462765680444837, Recall: 0.8508204917673469, F1: 0.848447335524872
Average GSM8K overall BERTScore: Precision: 0.8456899733903408, Recall: 0.8457275537545383, F1: 0.8456280138859749
Average SGSM Train/GSM8K overall BERTScore: Precision: 0.840354038294509, Recall: 0.8467633449492603, F1: 0.8434621846410483
Average MATHWELL overall BERTScore: Precision: 0.8551377776302168, Recall: 0.8551451701396069, F1: 0.8550444744559783
Average MATHWELL MaC overall BERTScore: Precision: 0.8570181962275119, Recall: 0.8570214159528, F1: 0.8569227768349703
Average MATHWELL MaC/MATHWELL all generations BERTScore: Precision: 0.8557673336183729, Recall: 0.855989014670848, F1: 0.8557811065066411
Average MATHWELL/GSM8K BERTScore: Precision: 0.8444644397634181, Recall: 0.8399244859777448, F1: 0.8421039568530696
Average llama overall BERTScore: Precision: 0.8549909737203499, Recall: 0.8549805880699796, F1: 0.8548465154370385
Average llama MaC overall BERTScore: Precision: 0.8579384546383824, Recall: 0.8579292715551625, F1: 0.8578176825258292
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8570634047179115, Recall: 0.8552948921646212, F1: 0.8560503375590901
Average llama MaC/GSM8K BERTScore: Precision: 0.8471580751102439, Recall: 0.8397599834988358, F1: 0.8433411447778373
Average llema overall BERTScore: Precision: 0.8430803649253441, Recall: 0.8430834780914754, F1: 0.8429309627056488
Average llema MaC overall BERTScore: Precision: 0.8535875200971283, Recall: 0.8533325084823776, F1: 0.8533714960159903
Average llema all generations/llema MaC overall BERTScore: Precision: 0.848080519014164, Recall: 0.8445131868954647, F1: 0.846173603754692
Average llema MaC/GSM8K BERTScore: Precision: 0.8429092120017267, Recall: 0.8390211404231603, F1: 0.840850367878897
Average mammoth overall BERTScore: Precision: 0.8600094575896767, Recall: 0.8600149131265514, F1: 0.8598918211121555
Average mammoth MaC overall BERTScore: Precision: 0.8636434873696536, Recall: 0.86367444563835, F1: 0.8635629409016555
Average mammoth all generations/mammoth MaC overall BERTScore: Precision: 0.8620930382652403, Recall: 0.8610207990470884, F1: 0.8614486537803139
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8531177363672455, Recall: 0.8408487366107795, F1: 0.8468445647593503
Average numglue overall BERTScore: Precision: 0.8152694408504069, Recall: 0.8152454651836157, F1: 0.8148550397938042
