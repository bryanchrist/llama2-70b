Average GSM8K overall BERTScore: Precision: 0.8471522494183646, Recall: 0.847014728585879, F1: 0.8469969493415621
Average MATHWELL Train overall BERTScore: Precision: 0.8502784208615621, Recall: 0.8510564319239723, F1: 0.8505710665570365
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8385263025893105, Recall: 0.8477788354317347, F1: 0.8430502842320337
Average MATHWELL overall BERTScore: Precision: 0.8529472214460373, Recall: 0.8554133501708507, F1: 0.8540826505661011
Average MATHWELL MaC overall BERTScore: Precision: 0.8549211949944496, Recall: 0.8580031839311123, F1: 0.8563688972353936
Average MATHWELL MaC/MATHWELL Train overall BERTScore: Precision: 0.8534447733693653, Recall: 0.8526850340949165, F1: 0.852974559044838
Average MATHWELL MaC/MATHWELL all generations BERTScore: Precision: 0.855183902835846, Recall: 0.856173060186704, F1: 0.8555822678248087
Average llama overall BERTScore: Precision: 0.8542998584210872, Recall: 0.8540104838848114, F1: 0.8540191255152225
Average llama MaC overall BERTScore: Precision: 0.8576101831972599, Recall: 0.8567372686326504, F1: 0.8570596746146679
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8572957245720757, Recall: 0.8557121141566171, F1: 0.8563816287702984
Average llema overall BERTScore: Precision: 0.8420517384290696, Recall: 0.8427451902866363, F1: 0.842240979129076
Average GSM8K overall BERTScore: Precision: 0.8469565209642053, Recall: 0.8461447440534831, F1: 0.8464618147432804
Average MATHWELL Train overall BERTScore: Precision: 0.8513518596410752, Recall: 0.8517021996945143, F1: 0.8514354492008686
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8403197825178504, Recall: 0.8461471973508596, F1: 0.8431420533314348
Average GSM8K overall BERTScore: Precision: 0.8469565209642053, Recall: 0.8461447440534831, F1: 0.8464618147432804
Average MATHWELL Train overall BERTScore: Precision: 0.8513518596410752, Recall: 0.8517021996945143, F1: 0.8514354492008686
Average MATHWELL Annotated overall BERTScore: Precision: 0.8443969956278801, Recall: 0.8440688721239566, F1: 0.8441400542721152
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8421765577539801, Recall: 0.8481686924293638, F1: 0.8450867074072361
Average MATHWELL Annotated/GSM8K overall BERTScore: Precision: 0.8405035879939795, Recall: 0.8459433189734816, F1: 0.8431292686328292
Average MATHWELL overall BERTScore: Precision: 0.8542634417189492, Recall: 0.8559481521023644, F1: 0.855009127079116
Average MATHWELL MaC overall BERTScore: Precision: 0.8559311995638741, Recall: 0.8570790422704485, F1: 0.8564082360612022
Average MATHWELL MaC/MATHWELL Train overall BERTScore: Precision: 0.8547390955940206, Recall: 0.8522132346271835, F1: 0.8533777722002978
Average MATHWELL MaC/MATHWELL all generations BERTScore: Precision: 0.8561087469566375, Recall: 0.856297265546436, F1: 0.856106817229314
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8466331116807587, Recall: 0.8413413157551847, F1: 0.8438908415684041
Average llama overall BERTScore: Precision: 0.8542358335256577, Recall: 0.854047078095542, F1: 0.8540021144072215
Average llama MaC overall BERTScore: Precision: 0.8577916333807839, Recall: 0.8575055886586507, F1: 0.8575399140675862
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8560642276258226, Recall: 0.8541825247703084, F1: 0.8549976828485537
Average llama MaC/GSM8K BERTScore: Precision: 0.8492369993040516, Recall: 0.8401760799717751, F1: 0.8445923418546938
Average llema overall BERTScore: Precision: 0.8426897490978241, Recall: 0.8431476764069663, F1: 0.8427685074647268
Average llema MaC overall BERTScore: Precision: 0.8533067850397145, Recall: 0.8533067850397145, F1: 0.8532173474724274
Average llema all generations/llema MaC overall BERTScore: Precision: 0.8484562948564204, Recall: 0.8444674874369691, F1: 0.8463331819380202
Average llema MaC/GSM8K BERTScore: Precision: 0.8485364828095203, Recall: 0.840709045812851, F1: 0.8445309536704203
Average mammoth overall BERTScore: Precision: 0.858730476000574, Recall: 0.8604984874937269, F1: 0.8594948509163327
Average mammoth MaC overall BERTScore: Precision: 0.8638068036066026, Recall: 0.8638068036066026, F1: 0.8637128331162491
Average mammoth all generations/mammoth MaC overall BERTScore: Precision: 0.8626276576348714, Recall: 0.8606136351291622, F1: 0.8615091008522681
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8551680223005158, Recall: 0.8418426455961806, F1: 0.8483671792617866
Average numglue overall BERTScore: Precision: 0.8073339698329568, Recall: 0.806794936567545, F1: 0.8064773639425635
Average MATHWELL Train overall BERTScore: Precision: 0.8519595927640796, Recall: 0.8527416401341558, F1: 0.8522530140385032
Average MATHWELL Annotated overall BERTScore: Precision: 0.8447176705524325, Recall: 0.8463437369793654, F1: 0.8454368771448731
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8412310455352068, Recall: 0.8474164121598006, F1: 0.8442316555917263
Average MATHWELL Annotated/GSM8K overall BERTScore: Precision: 0.8398681085556745, Recall: 0.8429979336321354, F1: 0.8413339368775486
Average MATHWELL MaC/MATHWELL Train overall BERTScore: Precision: 0.8519475573761032, Recall: 0.852475043876057, F1: 0.8521112772743119
Average MATHWELL Annotated/MATHWELL Train BERTScore: Precision: 0.8516618399739265, Recall: 0.8520580552592874, F1: 0.8517635877341032
Average asdiv overall BERTScore: Precision: 0.8612890245139598, Recall: 0.8697439480915665, F1: 0.8654352985024453
Average svamp overall BERTScore: Precision: 0.8604789712235331, Recall: 0.860896236602962, F1: 0.8606245523452759
Average gsmhard overall BERTScore: Precision: 0.8373232307314873, Recall: 0.8407965356945991, F1: 0.8389891711726785


 ### New Results ### 

Average GSM8K overall BERTScore: Precision: 0.8463350078031421, Recall: 0.8457823706323901, F1: 0.8459777488627368
Average MATHWELL Train overall BERTScore: Precision: 0.8517336996032132, Recall: 0.8521391431990597, F1: 0.8518413429018524
Average MATHWELL Train/GSM8K overall BERTScore: Precision: 0.8406809953004122, Recall: 0.8465386409797602, F1: 0.8435248461650477
Average MATHWELL overall BERTScore: Precision: 0.855087990603447, Recall: 0.855087990603447, F1: 0.854990834227562
Average MATHWELL MaC overall BERTScore: Precision: 0.8568606327202267, Recall: 0.8568606327202267, F1: 0.856763548810067
Average MATHWELL MaC/GSM8K BERTScore: Precision: 0.8462206601922182, Recall: 0.8403072216705227, F1: 0.843168612526241
Average llama overall BERTScore: Precision: 0.8545193456668854, Recall: 0.8545193456611633, F1: 0.8543819382953644
Average llama MaC overall BERTScore: Precision: 0.8574004992422523, Recall: 0.8574004992083984, F1: 0.8572935738656975
Average llama all generations/llama MaC overall BERTScore: Precision: 0.8566114011737191, Recall: 0.8548038839974981, F1: 0.8555844218837227
Average llama MaC/GSM8K BERTScore: Precision: 0.8491229394255424, Recall: 0.839475265346515, F1: 0.8441834707573974
Average llema overall BERTScore: Precision: 0.8431368972091675, Recall: 0.8431368972063065, F1: 0.8429839361667633
Average llema MaC overall BERTScore: Precision: 0.8533067850397145, Recall: 0.8533067850397145, F1: 0.8532173474724274
Average llema all generations/llema MaC overall BERTScore: Precision: 0.8483775781538428, Recall: 0.8445171670041434, F1: 0.8463217939051186
Average llema MaC/GSM8K BERTScore: Precision: 0.847917275736487, Recall: 0.8397503868011924, F1: 0.8437362130386074
Average mammoth overall BERTScore: Precision: 0.8595782812166214, Recall: 0.8595782812080384, F1: 0.8594555507640839
Average mammoth MaC overall BERTScore: Precision: 0.8638068036066026, Recall: 0.8638068036066026, F1: 0.8637128331162491
Average mammoth all generations/mammoth MaC overall BERTScore: Precision: 0.8622202548282487, Recall: 0.8605734646218164, F1: 0.8612879826971462
Average mammoth MaC/GSM8K BERTScore: Precision: 0.8551877734746252, Recall: 0.8410826649091073, F1: 0.8479968668577217
Average numglue overall BERTScore: Precision: 0.8100303893451889, Recall: 0.8091517146598962, F1: 0.8090287285524937
