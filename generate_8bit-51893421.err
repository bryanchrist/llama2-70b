  Running command git clone --quiet https://github.com/huggingface/peft.git /tmp/pip-install-uc02d389/peft_c0b3496c5fe346e39ab3b099c75f13d9
  Running command git clone --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-uc02d389/accelerate_a13ff3825a254a1e84fecbc3a70727e7
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/brc4cb/.conda/envs/falcon_40B/lib/libcudart.so'), PosixPath('/home/brc4cb/.conda/envs/falcon_40B/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.
Either way, this might cause trouble in the future:
If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.
  warn(msg)
Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 776/776 [00:00<00:00, 435kB/s]
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 609/609 [00:00<00:00, 422kB/s]
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]Downloading shards:  20%|██        | 3/15 [00:00<00:00, 29.87it/s]Downloading shards:  40%|████      | 6/15 [00:00<00:00, 29.46it/s]Downloading shards:  67%|██████▋   | 10/15 [00:00<00:00, 31.74it/s]Downloading shards:  93%|█████████▎| 14/15 [00:00<00:00, 30.31it/s]Downloading shards: 100%|██████████| 15/15 [00:00<00:00, 30.67it/s]
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:32<07:41, 32.97s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:58<06:14, 28.84s/it]Loading checkpoint shards:  20%|██        | 3/15 [01:24<05:28, 27.40s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [01:53<05:07, 27.98s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [02:21<04:40, 28.03s/it]Loading checkpoint shards:  40%|████      | 6/15 [02:49<04:11, 27.96s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [03:16<03:42, 27.80s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [03:43<03:11, 27.29s/it]Loading checkpoint shards:  60%|██████    | 9/15 [04:12<02:46, 27.81s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [04:41<02:21, 28.31s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [05:09<01:52, 28.10s/it]Loading checkpoint shards:  80%|████████  | 12/15 [05:35<01:22, 27.62s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [06:03<00:55, 27.70s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [06:29<00:27, 27.24s/it]Loading checkpoint shards: 100%|██████████| 15/15 [06:30<00:00, 19.40s/it]Loading checkpoint shards: 100%|██████████| 15/15 [06:30<00:00, 26.06s/it]
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
slurmstepd: error: *** JOB 51893421 ON udc-an34-1 CANCELLED AT 2023-08-03T19:47:10 DUE TO TIME LIMIT ***
