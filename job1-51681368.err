  Running command git clone --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-0nol5k35/transformers_3883b272881f42309343509740e7d9ff
  Running command git clone --quiet https://github.com/huggingface/peft.git /tmp/pip-install-0nol5k35/peft_039d105e37b4411a92ac8a5f58bce26c
  Running command git clone --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-0nol5k35/accelerate_376b10d4411b467dbec2f9475b01d812
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/brc4cb/.conda/envs/falcon_40B/lib/libcudart.so'), PosixPath('/home/brc4cb/.conda/envs/falcon_40B/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.
Either way, this might cause trouble in the future:
If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.
  warn(msg)
Downloading (…)lve/main/config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 647/647 [00:00<00:00, 607kB/s]
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Traceback (most recent call last):
  File "/gpfs/gpfs0/project/SDS/research/christ_research/Llama 2/llama2-70b/qlora.py", line 817, in <module>
    train()
  File "/gpfs/gpfs0/project/SDS/research/christ_research/Llama 2/llama2-70b/qlora.py", line 653, in train
    model = get_accelerate_model(args, checkpoint_dir)
  File "/gpfs/gpfs0/project/SDS/research/christ_research/Llama 2/llama2-70b/qlora.py", line 289, in get_accelerate_model
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 493, in from_pretrained
    return model_class.from_pretrained(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2197, in from_pretrained
    raise ValueError(
ValueError: `token` and `use_auth_token` are both specified. Please set only the argument `token`.
