  Running command git clone --quiet https://github.com/huggingface/peft.git /tmp/pip-install-8jej6q0f/peft_1fe1c3926a31436d8e236913f7c07ea4
  Running command git clone --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-8jej6q0f/accelerate_520e96cda731473abbe3c5ed5f56c411
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:06<01:31,  6.55s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:12<01:20,  6.16s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:18<01:12,  6.07s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:24<01:06,  6.04s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:30<01:00,  6.05s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:36<00:54,  6.04s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:42<00:49,  6.18s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:48<00:42,  6.11s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:54<00:36,  6.03s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:00<00:30,  6.00s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:06<00:24,  6.01s/it]Loading checkpoint shards:  80%|████████  | 12/15 [01:12<00:17,  5.96s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [01:18<00:11,  5.93s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [01:24<00:05,  5.84s/it]Loading checkpoint shards: 100%|██████████| 15/15 [01:24<00:00,  4.17s/it]Loading checkpoint shards: 100%|██████████| 15/15 [01:24<00:00,  5.63s/it]
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Traceback (most recent call last):
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora.py", line 823, in <module>
    train()
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora.py", line 694, in train
    data_module = make_data_module(tokenizer=tokenizer, args=args)
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora.py", line 591, in make_data_module
    dataset = load_data(args.dataset)
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora.py", line 555, in load_data
    raise NotImplementedError(f"Dataset {dataset_name} not implemented yet.")
NotImplementedError: Dataset ASDiv_GSM8K.json not implemented yet.
