

==> WARNING: A newer version of conda exists. <==
  current version: 23.5.2
  latest version: 24.5.0

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=24.5.0


WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-install-mk9mtism/transformers_597ec0003cd34a029d7566963d5d38bf
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl /tmp/pip-install-mk9mtism/trl_6ecf684764e2426fa5d910b0d0018b0a
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-mk9mtism/peft_546378416f7a49a38bc794314019934b
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-mk9mtism/accelerate_4e08cb52c7504d61b6a3e8f7cabcfcd9
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)


==> WARNING: A newer version of conda exists. <==
  current version: 23.5.2
  latest version: 24.5.0

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=24.5.0


/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Unused kwargs: ['use_auth_token']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]Downloading shards:   7%|â–‹         | 1/15 [00:46<10:48, 46.31s/it]Downloading shards:  13%|â–ˆâ–Ž        | 2/15 [01:39<10:51, 50.09s/it]Downloading shards:  20%|â–ˆâ–ˆ        | 3/15 [02:28<09:56, 49.68s/it]Downloading shards:  27%|â–ˆâ–ˆâ–‹       | 4/15 [03:18<09:07, 49.74s/it]/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/huggingface_hub/file_download.py:982: UserWarning: Not enough free disk space to download the file. The expected file size is: 9798.10 MB. The target location /home/brc4cb/.cache/huggingface/hub/models--meta-llama--Llama-2-70b-hf/blobs only has 4368.37 MB free disk space.
  warnings.warn(
Downloading shards:  27%|â–ˆâ–ˆâ–‹       | 4/15 [04:08<11:23, 62.12s/it]
Traceback (most recent call last):
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora_no_embed.py", line 855, in <module>
    train()
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora_no_embed.py", line 700, in train
    model = get_accelerate_model(args, checkpoint_dir, tokenizer)
  File "/sfs/weka/scratch/brc4cb/llama2-70b/qlora_no_embed.py", line 299, in get_accelerate_model
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3591, in from_pretrained
    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/hub.py", line 1079, in get_checkpoint_shard_files
    cached_filename = cached_file(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/hub.py", line 402, in cached_file
    resolved_file = hf_hub_download(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1221, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1367, in _hf_hub_download_to_cache_dir
    _download_to_tmp_and_move(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1884, in _download_to_tmp_and_move
    http_get(
OSError: [Errno 28] No space left on device
