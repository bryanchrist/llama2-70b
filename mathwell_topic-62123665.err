

==> WARNING: A newer version of conda exists. <==
  current version: 23.5.2
  latest version: 24.5.0

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=24.5.0


WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-install-n3cf8s5s/transformers_6cf284abb70a4665a26d2f2c10487685
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl /tmp/pip-install-n3cf8s5s/trl_0470b7fe5d834515964e7641f3cc29bb
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-n3cf8s5s/peft_1fc5051d00b8456a91a9eecdff32d153
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-n3cf8s5s/accelerate_bd46ba8d4411422b9d679edb84983e7a
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)


==> WARNING: A newer version of conda exists. <==
  current version: 23.5.2
  latest version: 24.5.0

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=24.5.0


/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]Downloading shards:   7%|▋         | 1/15 [03:38<51:03, 218.84s/it]Downloading shards:  13%|█▎        | 2/15 [07:04<45:42, 210.94s/it]Downloading shards:  20%|██        | 3/15 [10:24<41:12, 206.05s/it]Downloading shards:  27%|██▋       | 4/15 [13:53<37:59, 207.21s/it]Downloading shards:  33%|███▎      | 5/15 [17:09<33:53, 203.31s/it]Downloading shards:  40%|████      | 6/15 [20:34<30:33, 203.70s/it]Downloading shards:  47%|████▋     | 7/15 [24:19<28:04, 210.57s/it]Downloading shards:  53%|█████▎    | 8/15 [27:54<24:43, 211.99s/it]Downloading shards:  60%|██████    | 9/15 [31:21<21:04, 210.70s/it]Downloading shards:  67%|██████▋   | 10/15 [35:05<17:54, 214.82s/it]Downloading shards:  73%|███████▎  | 11/15 [38:44<14:23, 215.94s/it]Downloading shards:  80%|████████  | 12/15 [42:20<10:48, 216.09s/it]Downloading shards:  87%|████████▋ | 13/15 [45:55<07:11, 215.73s/it]Downloading shards:  93%|█████████▎| 14/15 [49:14<03:30, 210.72s/it]Downloading shards: 100%|██████████| 15/15 [49:26<00:00, 150.79s/it]Downloading shards: 100%|██████████| 15/15 [49:26<00:00, 197.79s/it]
Traceback (most recent call last):
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1557, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/integrations/bitsandbytes.py", line 13, in <module>
    import bitsandbytes as bnb
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/__init__.py", line 15, in <module>
    from .nn import modules
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/nn/__init__.py", line 17, in <module>
    from .triton_based_modules import (
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/nn/triton_based_modules.py", line 7, in <module>
    from bitsandbytes.triton.int8_matmul_mixed_dequantize import (
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/triton/int8_matmul_mixed_dequantize.py", line 12, in <module>
    from triton.ops.matmul_perf_model import early_config_prune, estimate_matmul_time
ModuleNotFoundError: No module named 'triton.ops'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/sfs/weka/scratch/brc4cb/llama2-70b/mathwell.py", line 82, in <module>
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3720, in from_pretrained
    hf_quantizer.preprocess_model(
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/quantizers/base.py", line 182, in preprocess_model
    return self._process_model_before_weight_loading(model, **kwargs)
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 232, in _process_model_before_weight_loading
    from ..integrations import get_keys_to_not_convert, replace_with_bnb_linear
  File "<frozen importlib._bootstrap>", line 1055, in _handle_fromlist
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1547, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1559, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):
No module named 'triton.ops'
