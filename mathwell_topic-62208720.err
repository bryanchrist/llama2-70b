/var/spool/slurm/slurmd/job62208720/slurm_script: line 35: export PYTHONPATH=/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages:/home/brc4cb/.conda/envs/mathwell/bin:/home/brc4cb/.conda/envs/mathwell/bin:/apps/software/standard/core/anaconda/2023.07-py3.11/condabin:/apps/software/standard/core/anaconda/2023.07-py3.11:/apps/software/standard/core/anaconda/2023.07-py3.11/sbin:/apps/software/standard/core/anaconda/2023.07-py3.11/bin:/opt/mam/9.1.2/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/slurm/current/bin:/opt/singularity/current/bin:/opt/rci/bin:/share/rci_apps/common/bin:/share/resources/HPCtools:/opt/mam/current/bin:/opt/apptainer/current/bin: No such file or directory
/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:02<00:41,  3.00s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:05<00:36,  2.85s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:08<00:33,  2.79s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:11<00:30,  2.80s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:13<00:27,  2.76s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:16<00:24,  2.75s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:19<00:22,  2.76s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:22<00:20,  2.89s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:25<00:17,  2.95s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:28<00:14,  2.98s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:31<00:12,  3.00s/it]Loading checkpoint shards:  80%|████████  | 12/15 [00:34<00:08,  2.95s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [00:37<00:05,  2.97s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [00:40<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:40<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:40<00:00,  2.72s/it]
Traceback (most recent call last):
  File "/sfs/weka/scratch/brc4cb/llama2-70b/mathwell.py", line 98, in <module>
    model = PeftModel.from_pretrained(model, adapter_path)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/peft/peft_model.py", line 430, in from_pretrained
    model.load_adapter(model_id, adapter_name, is_trainable=is_trainable, **kwargs)
  File "/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/peft/peft_model.py", line 988, in load_adapter
    load_result = set_peft_model_state_dict(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/peft/utils/save_and_load.py", line 353, in set_peft_model_state_dict
    load_result = model.load_state_dict(peft_model_state_dict, strict=False)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/brc4cb/.conda/envs/mathwell/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2189, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PeftModelForCausalLM:
	size mismatch for base_model.model.model.embed_tokens.weight: copying a param with shape torch.Size([32064, 8192]) from checkpoint, the shape in current model is torch.Size([32000, 8192]).
	size mismatch for base_model.model.lm_head.weight: copying a param with shape torch.Size([32064, 8192]) from checkpoint, the shape in current model is torch.Size([32000, 8192]).
