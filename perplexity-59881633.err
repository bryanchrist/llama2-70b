

==> WARNING: A newer version of conda exists. <==
  current version: 23.5.2
  latest version: 24.3.0

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=24.3.0


WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-na4z6134/peft_f5c4cc8abf3e4c2d8cd7584f17056595
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-na4z6134/accelerate_4abd96c61dd64718bbcbb9b8e64d11ee
ERROR: Cannot install -r requirements.txt (line 2), -r requirements.txt (line 3), -r requirements.txt (line 6) and huggingface_hub==0.16.4 because these package versions have conflicting dependencies.
ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)
WARNING: Ignoring invalid distribution -riton-nightly (/sfs/qumulo/qhome/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages)


==> WARNING: A newer version of conda exists. <==
  current version: 23.5.2
  latest version: 24.3.0

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=24.3.0


/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 15/15 [00:00<00:00, 1983.18it/s]
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:03<00:48,  3.45s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:06<00:41,  3.16s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:09<00:38,  3.17s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:12<00:34,  3.17s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:16<00:33,  3.32s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:19<00:30,  3.40s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:23<00:27,  3.44s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:26<00:24,  3.45s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:30<00:20,  3.37s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:33<00:16,  3.31s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:36<00:13,  3.37s/it]Loading checkpoint shards:  80%|████████  | 12/15 [00:40<00:09,  3.33s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [00:43<00:06,  3.28s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [00:46<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:46<00:00,  2.39s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:46<00:00,  3.12s/it]
You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')
