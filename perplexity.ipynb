{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0e4d8-1bcc-41f5-8489-b1e82e088e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U torch==2.0.1 bitsandbytes==0.40.2\n",
    "%pip install -q -U transformers==4.35.2 peft==0.4.0 accelerate==0.21.0\n",
    "%pip install -q -U datasets py7zr einops tensorboardX\n",
    "!pip install evaluate\n",
    "# Add installed cuda runtime to path for bitsandbytes\n",
    "import os\n",
    "import nvidia\n",
    "\n",
    "cuda_install_dir = '/'.join(nvidia.__file__.split('/')[:-1]) + '/cuda_runtime/lib/'\n",
    "os.environ['LD_LIBRARY_PATH'] =  cuda_install_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d0d6d-26db-4cd9-9c82-ba6929a0cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Path to your env.txt file\n",
    "env_file_path = 'data/env.txt'\n",
    "\n",
    "# Read and set environment variables\n",
    "with open(env_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        key, value = line.strip().split('=')\n",
    "        os.environ[key] = value\n",
    "token = os.environ['huggingface_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47c782-3db1-40f1-b3ee-25967e1ad0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"meta-llama/Llama-2-70b-hf\"   # Specify the path to the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_path,\n",
    "  device_map='auto',\n",
    "  load_in_4bit=True,\n",
    "  max_memory=max_memory,\n",
    "  do_sample=True,\n",
    "  torch_dtype=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd24884-493c-48de-b125-f461c2556e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_models.csv')\n",
    "gsm8k_all = pd.read_csv('data/gsm8k_all.csv')\n",
    "gsm8k_questions = pd.read_csv('data/gsm8k_questions.csv')\n",
    "mathwell_all = pd.read_csv('data/mathwell_annotations.csv')\n",
    "mathwell_all_good = mathwell_all[mathwell_all['good']==1]\n",
    "llama = df[df['model']=='llama']\n",
    "llama_good = llama[llama['good']==1]\n",
    "llema = df[df['model']=='llema']\n",
    "llema_good = llema[llema['good']==1]\n",
    "mathwell = df[df['model']=='mathwell']\n",
    "mathwell_good = mathwell[mathwell['good']==1]\n",
    "mammoth = df[df['model']=='mammoth']\n",
    "mammoth_good = mammoth[mammoth['good']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9269ef-8420-4355-bfcf-41f06768b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(df):\n",
    "    ppls = []\n",
    "    for i in range(0, len(df)):\n",
    "        text = \"Question: \" + df.iloc[i]['question'] + \"\\n\" + \"Solution:\\n\" + df.iloc[i]['solution']\n",
    "        inputs = tokenizer(text, return_tensors = \"pt\")\n",
    "        loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "        ppl = torch.exp(loss)\n",
    "        ppls.append(ppl)\n",
    "    return ppls\n",
    "\n",
    "def perplexity_question(df):\n",
    "    ppls = []\n",
    "    for i in range(0, len(df)):\n",
    "        text = df.iloc[i]['question']\n",
    "        inputs = tokenizer(text, return_tensors = \"pt\")\n",
    "        loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "        ppl = torch.exp(loss)\n",
    "        ppls.append(ppl)\n",
    "    return ppls\n",
    "\n",
    "def perplexity_gsm(df):\n",
    "    ppls = []\n",
    "    for i in range(0, len(df)):\n",
    "        text = df.iloc[i]['output']\n",
    "        inputs = tokenizer(text, return_tensors = \"pt\")\n",
    "        loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "        ppl = torch.exp(loss)\n",
    "        ppls.append(ppl)\n",
    "    return ppls\n",
    "\n",
    "def perplexity_gsm_question(df):\n",
    "    ppls = []\n",
    "    for i in range(0, len(df)):\n",
    "        text = df.iloc[i]['instruction']\n",
    "        inputs = tokenizer(text, return_tensors = \"pt\")\n",
    "        loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "        ppl = torch.exp(loss)\n",
    "        ppls.append(ppl)\n",
    "    return ppls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623868b-8328-4a08-be4e-98af879a90af",
   "metadata": {},
   "source": [
    "## GSM8K Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616ef80-3def-4a53-ab57-11fae109f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm8k_ppl = perplexity_gsm(gsm8k_all)\n",
    "gsm8k_question_ppl = perplexity_gsm_question(gsm8k_questions)\n",
    "print(f'Average overall perplexity: {np.mean(gsm8k_ppl)} Standard Deviation: {np.std(gsm8k_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(gsm8k_question_ppl)} Standard Deviation: {np.std(gsm8k_question_ppl)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3583898-5b7c-4f57-9822-eeea2e0f6a8e",
   "metadata": {},
   "source": [
    "## MATHWELL Annotated Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0520bb9f-5e2f-41a6-b585-db0929f346e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mathwell_all_ppl = perplexity(mathwell_all)\n",
    "mathwell_all_question_ppl = perplexity_question(mathwell_all)\n",
    "print(f'Average overall perplexity: {np.mean(mathwell_all_ppl)} Standard Deviation: {np.std(mathwell_all_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(mathwell_all_question_ppl)} Standard Deviation: {np.std(mathwell_all_question_ppl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aefb34-9c98-49cc-9a80-cabf7633c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "mathwell_all_good_ppl = perplexity(mathwell_all_good)\n",
    "mathwell_all_good_question_ppl = perplexity_question(mathwell_all_good)\n",
    "print(f'Average overall perplexity: {np.mean(mathwell_all_good_ppl)} Standard Deviation: {np.std(mathwell_all_good_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(mathwell_all_good_question_ppl)} Standard Deviation: {np.std(mathwell_all_good_question_ppl)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b98b6-56cc-4220-b992-d480f9121735",
   "metadata": {},
   "source": [
    "## MATHWELL Final Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9199a8-8371-4892-9196-1756e27dc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "mathwell_ppl = perplexity(mathwell)\n",
    "mathwell_question_ppl = perplexity_question(mathwell)\n",
    "print(f'Average overall perplexity: {np.mean(mathwell_ppl)} Standard Deviation: {np.std(mathwell_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(mathwell_question_ppl)} Standard Deviation: {np.std(mathwell_question_ppl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c6d33-2396-452a-9be3-b89bf24eb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mathwell_good_ppl = perplexity(mathwell_good)\n",
    "mathwell_good_question_ppl = perplexity_question(mathwell_good)\n",
    "print(f'Average overall perplexity: {np.mean(mathwell_good_ppl)} Standard Deviation: {np.std(mathwell_good_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(mathwell_good_question_ppl)} Standard Deviation: {np.std(mathwell_good_question_ppl)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291b7a6-20e9-4e04-8812-6ca07026460f",
   "metadata": {},
   "source": [
    "## Llama Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ed867-6756-4198-b99d-eff93fa3471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_ppl = perplexity(llama)\n",
    "llama_question_ppl = perplexity_question(llama)\n",
    "print(f'Average overall perplexity: {np.mean(llama_ppl)} Standard Deviation: {np.std(llama_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(llama_question_ppl)} Standard Deviation: {np.std(llama_question_ppl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de958a7c-a502-4e8f-a09f-f1635055f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_good_ppl = perplexity(llama_good)\n",
    "llama_good_question_ppl = perplexity_question(llama_good)\n",
    "print(f'Average overall perplexity: {np.mean(llama_good_ppl)} Standard Deviation: {np.std(llama_good_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(llama_good_question_ppl)} Standard Deviation: {np.std(llama_good_question_ppl)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25ceee-4ac9-4f08-a49e-6a563495ef24",
   "metadata": {},
   "source": [
    "## Llemma Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61744f-d6f2-4003-bbcc-6d886f5f3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "llema_ppl = perplexity(llema)\n",
    "llema_question_ppl = perplexity_question(llema)\n",
    "print(f'Average overall perplexity: {np.mean(llema_ppl)} Standard Deviation: {np.std(llema_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(llema_question_ppl)} Standard Deviation: {np.std(llema_question_ppl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfae03-70e8-4bbd-b772-42bf54571099",
   "metadata": {},
   "outputs": [],
   "source": [
    "llema_good_ppl = perplexity(llema_good)\n",
    "llema_good_question_ppl = perplexity_question(llema_good)\n",
    "print(f'Average overall perplexity: {np.mean(llema_good_ppl)} Standard Deviation: {np.std(llema_good_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(llema_good_question_ppl)} Standard Deviation: {np.std(llema_good_question_ppl)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af229b24-1082-40fd-94e8-170c5489dba1",
   "metadata": {},
   "source": [
    "## Mammoth Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620263bd-c7af-4b7c-a5e6-3f64be48f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "mammoth_ppl = perplexity(mammoth)\n",
    "mammoth_question_ppl = perplexity_question(mammoth)\n",
    "print(f'Average overall perplexity: {np.mean(mammoth_ppl)} Standard Deviation: {np.std(mammoth_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(mammoth_question_ppl)} Standard Deviation: {np.std(mammoth_question_ppl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012af04-a264-4eb9-b36a-b2691fc28add",
   "metadata": {},
   "outputs": [],
   "source": [
    "mammoth_good_ppl = perplexity(mammoth_good)\n",
    "mammoth_good_question_ppl = perplexity_question(mammoth_good)\n",
    "print(f'Average overall perplexity: {np.mean(mammoth_good_ppl)} Standard Deviation: {np.std(mammoth_good_ppl)}')\n",
    "print(f'Average overall perplexity for questions only: {np.mean(mammoth_good_question_ppl)} Standard Deviation: {np.std(mammoth_good_question_ppl)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
