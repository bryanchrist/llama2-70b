  Running command git clone --quiet https://github.com/huggingface/peft.git /tmp/pip-install-x0sqjvz4/peft_5c45edd948a143af883001b48ea85f67
  Running command git clone --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-x0sqjvz4/accelerate_5cebff78c24344b1b6493e054fade52f
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/home/brc4cb/.conda/envs/falcon_40B/lib/python3.9/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:04<01:08,  4.86s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:08<00:52,  4.05s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:12<00:46,  3.89s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:15<00:41,  3.79s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:19<00:37,  3.73s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:23<00:34,  3.84s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:27<00:30,  3.80s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:30<00:26,  3.77s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:34<00:22,  3.79s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:38<00:18,  3.70s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:41<00:14,  3.69s/it]Loading checkpoint shards:  80%|████████  | 12/15 [00:45<00:11,  3.69s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [00:49<00:07,  3.70s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [00:52<00:03,  3.65s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:52<00:00,  2.62s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:52<00:00,  3.53s/it]
WARNING:root:The `device_map` argument is not provided. We will override the device_map argument. to set the entire model on the current device. If you want to set the model on multiple devices, please provide a custom `device_map` argument.
WARNING:datasets.builder:Found cached dataset csv (/home/brc4cb/.cache/huggingface/datasets/csv/default-10416fda93fda02b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 495.25it/s]
WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/brc4cb/.cache/huggingface/datasets/csv/default-10416fda93fda02b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-789e2502999e7416.arrow
WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/brc4cb/.cache/huggingface/datasets/csv/default-10416fda93fda02b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-789e2502999e7416.arrow
WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/brc4cb/.cache/huggingface/datasets/csv/default-10416fda93fda02b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-789e2502999e7416.arrow
WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/brc4cb/.cache/huggingface/datasets/csv/default-10416fda93fda02b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-db79731672741871.arrow
Map:   0%|          | 0/58 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
                                                  WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/brc4cb/.cache/huggingface/datasets/csv/default-10416fda93fda02b/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-8a5fe88606ad719d.arrow
Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 369kB/s]
Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]Downloading model.safetensors:  14%|█▍        | 62.9M/440M [00:00<00:00, 537MB/s]Downloading model.safetensors:  29%|██▊       | 126M/440M [00:00<00:00, 584MB/s] Downloading model.safetensors:  43%|████▎     | 189M/440M [00:00<00:00, 601MB/s]Downloading model.safetensors:  57%|█████▋    | 252M/440M [00:00<00:00, 601MB/s]Downloading model.safetensors:  71%|███████▏  | 315M/440M [00:00<00:00, 599MB/s]Downloading model.safetensors:  88%|████████▊ | 388M/440M [00:00<00:00, 609MB/s]Downloading model.safetensors: 100%|██████████| 440M/440M [00:00<00:00, 601MB/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 23.8kB/s]
Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 34.8MB/s]
Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 49.2MB/s]
Traceback (most recent call last):
  File "/gpfs/gpfs0/project/SDS/research/christ_research/Llama 2/llama2-70b/ppo.py", line 162, in <module>
    model_name=model_name,    
NameError: name 'model_name' is not defined
