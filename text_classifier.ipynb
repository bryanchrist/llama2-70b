{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466bcfe9-b0d9-4731-9982-a0b220a41d47",
   "metadata": {
    "tags": []
   },
   "source": [
    "#!conda install -y cudatoolkit\n",
    "#!pip install bitsandbytes\n",
    "!pip install transformers==4.33.2\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install peft\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112ae58f-3049-4f48-991a-bb7a4be92136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting evaluate\n",
      "  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (13.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U torch==2.0.1 bitsandbytes==0.40.2\n",
    "%pip install -q -U transformers==4.31.0 peft==0.4.0 accelerate==0.21.0\n",
    "%pip install -q -U datasets py7zr einops tensorboardX\n",
    "!pip install evaluate\n",
    "# Add installed cuda runtime to path for bitsandbytes\n",
    "import os\n",
    "import nvidia\n",
    "\n",
    "cuda_install_dir = '/'.join(nvidia.__file__.split('/')[:-1]) + '/cuda_runtime/lib/'\n",
    "os.environ['LD_LIBRARY_PATH'] =  cuda_install_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7773e8-3948-4ad0-a8d1-a0d3523fc87a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "#sys.path.append(\"/home/sagemaker-user/bitsandbytes\")\n",
    "#os.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib/'\n",
    "from os.path import exists, join, isdir\n",
    "from dataclasses import dataclass, field\n",
    "import sys\n",
    "from typing import Optional, Dict, Sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "#import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "torch.cuda.init()\n",
    "print(torch.cuda.is_available())\n",
    "import os\n",
    "#os.environ['TRANSFORMERS_CACHE'] = '/project/SDS/research/christ_research/Llama 2/llama2-7b/cache'\n",
    "import transformers\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import argparse\n",
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForCausalLM,\n",
    "#     set_seed,\n",
    "#     Seq2SeqTrainer,\n",
    "# #    BitsAndBytesConfig,\n",
    "#     LlamaTokenizer\n",
    "\n",
    "# )\n",
    "from datasets import load_dataset, Dataset\n",
    "import evaluate\n",
    "\n",
    "# from peft import (\n",
    "#     prepare_model_for_kbit_training,\n",
    "#     LoraConfig,\n",
    "#     get_peft_model,\n",
    "#     PeftModel,\n",
    "#     TaskType\n",
    "# )\n",
    "#from peft.tuners.lora import LoraLayer\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "#from dotenv import load_dotenv\n",
    "import os\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Load the environmental variables from the .env file\n",
    "#load_dotenv()\n",
    "\n",
    "#token = os.getenv('text_classifier_token')\n",
    "\n",
    "#from huggingface_hub import login\n",
    "#login(token = token)\n",
    "\n",
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c0f971-5e46-4441-a63a-0b90433ec759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc37f2d5-6f77-484f-ba8f-624d29246d32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: LeBron James is 6 feet 9 inches tall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: The volleyball team has 12 members. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>742</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: There are 50 cars in a parking lot. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>414</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: In Super Mario, the mushroom power-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1519</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Spiderman can spin 10 webs in 15 min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1496</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Patrick Mahomes has 200 touchdowns. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Barbie is a fashionista. She has 300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: A cheerleading squad of 20 members i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: The 6 Power Rangers each have a Mega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: 4000 people are at a soccer game. 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  label                                               text\n",
       "0           834      1  Question: LeBron James is 6 feet 9 inches tall...\n",
       "1          1329      1  Question: The volleyball team has 12 members. ...\n",
       "2           742      1  Question: There are 50 cars in a parking lot. ...\n",
       "3           414      1  Question: In Super Mario, the mushroom power-u...\n",
       "4          1519      1  Question: Spiderman can spin 10 webs in 15 min...\n",
       "..          ...    ...                                                ...\n",
       "979        1496      1  Question: Patrick Mahomes has 200 touchdowns. ...\n",
       "980         906      1  Question: Barbie is a fashionista. She has 300...\n",
       "981         403      0  Question: A cheerleading squad of 20 members i...\n",
       "982        1063      0  Question: The 6 Power Rangers each have a Mega...\n",
       "983         921      0  Question: 4000 people are at a soccer game. 10...\n",
       "\n",
       "[984 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/appropriateness.csv')\n",
    "df['label'] = df['label'].astype('int')\n",
    "pos = df[df['label']==1]\n",
    "neg = df[df['label']==0]\n",
    "neg_len = len(neg)\n",
    "pos = pos.sample(n = neg_len, replace = False)\n",
    "df2 = pd.concat([pos, neg])\n",
    "df2 = df2.sample(frac=1)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.to_csv('data/appropriateness_balanced.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb896c6f-685f-4ceb-a4bf-e39e9777d139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06dc0484fe64e1c849409d5b06b470f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31af0b85fea4462c813a6526de0d0509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d28e76b73514b53b27d30901d43432f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files=\"data/appropriateness_balanced.csv\")\n",
    "#dataset = load_dataset('csv', data_files=\"balanced.csv\")\n",
    "\n",
    "# Get the total number of examples in the dataset\n",
    "# total_examples = len(dataset['train'])\n",
    "\n",
    "# # Calculate the sizes of the training, test, and validation sets\n",
    "# train_size = int(0.8 * total_examples)\n",
    "# test_size = int(0.1 * total_examples)\n",
    "# valid_size = total_examples - train_size - test_size\n",
    "\n",
    "# # Manually split the dataset into training, test, and validation sets\n",
    "# train_dataset = dataset['train'].shuffle(seed=42).select(range(train_size))\n",
    "# test_dataset = dataset['train'].shuffle(seed=42).select(range(train_size, train_size + test_size))\n",
    "# valid_dataset = dataset['train'].shuffle(seed=42).select(range(train_size + test_size, total_examples))\n",
    "\n",
    "dataset_train_valid_test = dataset['train'].train_test_split(test_size = .2, seed = 42)\n",
    "dataset_valid_test = dataset_train_valid_test['test'].train_test_split(test_size = .5, seed = 42)\n",
    "# Create a DatasetDict to hold the splits\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': dataset_train_valid_test['train'],\n",
    "    'test': dataset_valid_test['train'],\n",
    "    'valid': dataset_valid_test['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a644a1cf-f91a-4e10-a14e-e5d69d732b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0.1': 922,\n",
       " 'Unnamed: 0': 422,\n",
       " 'label': 1,\n",
       " 'text': 'Question: Captain Marvel has 3000 vibranium-powered punches. She uses 200 punches in the morning, 400 punches in the afternoon, and 100 punches in the evening. How many vibranium-powered punches does she have left?\\nSolution:\\ndef solution():\\n    #Captain Marvel started with 3000 punches\\n    punches_initial = 3000\\n    #She used 200 in the morning\\n    punches_morning = 200\\n    #400 in the afternoon\\n    punches_afternoon = 400\\n    #100 in the evening\\n    punches_evening = 100\\n    #The answer is\\n    result = punches_initial - punches_morning - punches_afternoon - punches_evening\\n    return result\\nAnswer: 2300'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_valid_dataset['valid'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f73f4f87-32dc-47ac-ad2a-66b9fec1d1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468ace4d29234dfda3369215ceb1bc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/787 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5748244d9494f0bae9e18bb396afa93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a96ccad5134a679a6abecec07f859d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set up tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=True)\n",
    "# tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "#tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "\n",
    "#Preprocess and collate data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train_test_valid_dataset = train_test_valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3dd6cf2f-2bb8-49b9-9ff9-c08f4620006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "#Prepare evaluation function\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# roc_auc = evaluate.load(\"roc_auc\")\n",
    "\n",
    "# import numpy as np\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     return roc_auc.compute(prediction_scores=predictions, references=labels)\n",
    "\n",
    "#Training\n",
    "id2label = {0: \"NOT APPROPRIATE\", 1: \"APPROPRIATE\"}\n",
    "label2id = {\"NOT APPROPRIATE\": 0, \"APPROPRIATE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "580c59ec-1929-4c52-9d7d-508a4d443de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Import model\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"meta-llama/Llama-2-7b-hf\", num_labels=2, id2label=id2label, label2id=label2id,\n",
    "#         use_auth_token=True,  \n",
    "#       # max_memory=max_memory,\n",
    "#       # torch_dtype=torch.bfloat16, \n",
    "#       device_map = 'auto',\n",
    "#         quantization_config=BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type='nf4'))\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id,\n",
    "#         use_auth_token=True,  \n",
    "#       # max_memory=max_memory,\n",
    "#       # torch_dtype=torch.bfloat16, \n",
    "#         quantization_config=BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type='nf4'))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb59e8ba-2a7e-4580-a53f-3658c730ac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 05:17, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.321921</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472435</td>\n",
       "      <td>0.858586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437931</td>\n",
       "      <td>0.858586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463053</td>\n",
       "      <td>0.858586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.482812</td>\n",
       "      <td>0.838384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518507</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.646680</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.524509</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.549167</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.618347</td>\n",
       "      <td>0.838384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.551094</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.647667</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.808081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.768419</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.918770</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.899567</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'label', 'text', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 98\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#NEWLY ADDED\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.1,\n",
    "# )      \n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "#END NEWLY ADDED\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"text_classifier_llama\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=1,\n",
    "#   # auto_find_batch_size = True,\n",
    "#     num_train_epochs=8,\n",
    "#     weight_decay=0.01,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True, \n",
    "#     bf16=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"appropriateness_classifier\",\n",
    "    learning_rate=.0001,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=16,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_test_valid_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_train_test_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()\n",
    "print(tokenized_train_test_valid_dataset[\"test\"])\n",
    "test_input_data = tokenized_train_test_valid_dataset[\"test\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fcd3e1c-1914-477e-91f3-7df29b9093a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4093845784664154,\n",
       " 'eval_accuracy': 0.8469387755102041,\n",
       " 'eval_runtime': 0.5556,\n",
       " 'eval_samples_per_second': 176.378,\n",
       " 'eval_steps_per_second': 12.598,\n",
       " 'epoch': 16.0}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions = trainer.predict(test_dataset=test_input_data)\n",
    "# print(predictions)\n",
    "trainer.evaluate(eval_dataset = tokenized_train_test_valid_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ac40d49-42e6-4c69-8e0c-e7834e6a265a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.6207591 ,  0.6736535 ],\n",
       "       [ 1.0703156 , -1.0787371 ],\n",
       "       [ 1.0732976 , -1.083002  ],\n",
       "       [ 1.0771855 , -1.0870489 ],\n",
       "       [ 1.0770115 , -1.0839195 ],\n",
       "       [ 1.0791233 , -1.0896196 ],\n",
       "       [-0.8348101 ,  0.954373  ],\n",
       "       [-0.7923826 ,  0.8939277 ],\n",
       "       [-0.4819457 ,  0.4984986 ],\n",
       "       [-0.8402348 ,  0.957724  ],\n",
       "       [ 1.0282779 , -1.0092639 ],\n",
       "       [ 0.97511965, -0.9188721 ],\n",
       "       [ 0.94950694, -0.8858211 ],\n",
       "       [ 1.0813584 , -1.0934119 ],\n",
       "       [-0.91332245,  1.073796  ],\n",
       "       [-0.8381578 ,  0.94643205],\n",
       "       [ 0.95713544, -0.907661  ],\n",
       "       [-0.8014436 ,  0.8927865 ],\n",
       "       [ 1.06014   , -1.0623937 ],\n",
       "       [-0.76129806,  0.8426286 ],\n",
       "       [-0.690245  ,  0.754299  ],\n",
       "       [ 0.75947154, -0.7635017 ],\n",
       "       [ 0.98622674, -0.93695325],\n",
       "       [-0.8832992 ,  1.0191603 ],\n",
       "       [ 1.0769575 , -1.0843459 ],\n",
       "       [ 0.99102783, -0.9393181 ],\n",
       "       [-0.78705055,  0.88623387],\n",
       "       [-0.51369905,  0.53663653],\n",
       "       [-0.8794544 ,  1.0126878 ],\n",
       "       [-0.7683956 ,  0.8472914 ],\n",
       "       [ 1.0627216 , -1.061378  ],\n",
       "       [ 1.0460857 , -1.0445795 ],\n",
       "       [ 0.76965195, -0.76058644],\n",
       "       [-0.8927258 ,  1.0402671 ],\n",
       "       [-0.6541826 ,  0.7165093 ],\n",
       "       [ 0.7769393 , -0.7729017 ],\n",
       "       [-0.8976477 ,  1.0493561 ],\n",
       "       [ 1.0777477 , -1.0857255 ],\n",
       "       [ 0.9730041 , -0.9198705 ],\n",
       "       [ 1.078505  , -1.0889914 ],\n",
       "       [-0.6823079 ,  0.75282156],\n",
       "       [-0.7937462 ,  0.87708503],\n",
       "       [-0.8394984 ,  0.95411575],\n",
       "       [ 1.0679803 , -1.0703157 ],\n",
       "       [ 0.79597133, -0.7846268 ],\n",
       "       [ 1.0753578 , -1.0844592 ],\n",
       "       [-0.5945307 ,  0.6313805 ],\n",
       "       [-0.6229815 ,  0.6707864 ],\n",
       "       [ 1.045595  , -1.0391145 ],\n",
       "       [-0.82222176,  0.93190795],\n",
       "       [ 0.99536395, -0.95752573],\n",
       "       [-0.8701015 ,  1.0029789 ],\n",
       "       [-0.73651487,  0.8180508 ],\n",
       "       [ 0.76693827, -0.7633353 ],\n",
       "       [ 1.0772958 , -1.0857929 ],\n",
       "       [-0.8270372 ,  0.9397027 ],\n",
       "       [ 1.0674888 , -1.074643  ],\n",
       "       [-0.86734414,  0.99452007],\n",
       "       [ 1.078276  , -1.0856749 ],\n",
       "       [ 0.7307657 , -0.72848386],\n",
       "       [-0.80065274,  0.9035023 ],\n",
       "       [ 1.0018163 , -0.9678033 ],\n",
       "       [ 1.0814193 , -1.0917867 ],\n",
       "       [ 1.077795  , -1.088632  ],\n",
       "       [ 1.0243627 , -1.0031182 ],\n",
       "       [-0.6273028 ,  0.68220985],\n",
       "       [ 0.5205572 , -0.5478919 ],\n",
       "       [-0.87442094,  1.0025482 ],\n",
       "       [-0.77175766,  0.8490691 ],\n",
       "       [ 1.0781951 , -1.0892595 ],\n",
       "       [ 0.52755755, -0.56319475],\n",
       "       [ 1.067734  , -1.0729066 ],\n",
       "       [ 1.0404495 , -1.0325423 ],\n",
       "       [-0.61826795,  0.6687197 ],\n",
       "       [-0.81757164,  0.91019106],\n",
       "       [-0.8691    ,  0.99470216],\n",
       "       [-0.21013792,  0.17513102],\n",
       "       [-0.8104555 ,  0.9154937 ],\n",
       "       [-0.8255087 ,  0.9373098 ],\n",
       "       [ 1.0258039 , -1.0040925 ],\n",
       "       [ 1.0743668 , -1.0842104 ],\n",
       "       [-0.6700294 ,  0.7349247 ],\n",
       "       [-0.8030599 ,  0.8997568 ],\n",
       "       [ 1.0566286 , -1.0606872 ],\n",
       "       [ 1.0752625 , -1.0851341 ],\n",
       "       [ 1.0114145 , -0.9823754 ],\n",
       "       [ 1.0684693 , -1.074119  ],\n",
       "       [-0.7054477 ,  0.77928984],\n",
       "       [-0.8782934 ,  1.0212533 ],\n",
       "       [ 0.750338  , -0.7477421 ],\n",
       "       [-0.88692564,  1.0264585 ],\n",
       "       [ 1.0743651 , -1.0844494 ],\n",
       "       [-0.76014125,  0.833134  ],\n",
       "       [-0.7975718 ,  0.8953189 ],\n",
       "       [ 1.080592  , -1.0920861 ],\n",
       "       [ 1.076832  , -1.0842227 ],\n",
       "       [-0.8512484 ,  0.97794056],\n",
       "       [-0.83311296,  0.94488245]], dtype=float32), label_ids=array([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1]), metrics={'test_loss': 0.4093845784664154, 'test_accuracy': 0.8469387755102041, 'test_runtime': 0.5448, 'test_samples_per_second': 179.88, 'test_steps_per_second': 12.849})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset = tokenized_train_test_valid_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a8cbd-220e-4173-ae80-b4240e4b798e",
   "metadata": {},
   "source": [
    "## Solvability Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "07f390cc-1c07-47ab-8dc0-4279db01f08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: The lacrosse team has 54 sticks. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Spiderman has 20 spiderwebs. He uses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Patrick Mahomes has 2000 passing yar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: A field hockey game has 11 players o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>765</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Iron Man has 152 armor suits. He has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: The 2:00 PM train from Penn Station ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1634</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: 2000 people were at a rally. 1000 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: In the Mushroom Kingdom, there are 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: 5 cats and 4 dogs are for sale at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: A 100-pound sack of onions has 100 o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  label                                               text\n",
       "0           603      1  Question: The lacrosse team has 54 sticks. The...\n",
       "1          1440      0  Question: Spiderman has 20 spiderwebs. He uses...\n",
       "2          1201      1  Question: Patrick Mahomes has 2000 passing yar...\n",
       "3          1594      1  Question: A field hockey game has 11 players o...\n",
       "4           765      0  Question: Iron Man has 152 armor suits. He has...\n",
       "..          ...    ...                                                ...\n",
       "447         300      0  Question: The 2:00 PM train from Penn Station ...\n",
       "448        1634      1  Question: 2000 people were at a rally. 1000 of...\n",
       "449          71      0  Question: In the Mushroom Kingdom, there are 1...\n",
       "450         117      0  Question: 5 cats and 4 dogs are for sale at an...\n",
       "451         616      0  Question: A 100-pound sack of onions has 100 o...\n",
       "\n",
       "[452 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/solvability.csv')\n",
    "df['label'] = df['label'].astype('int')\n",
    "pos = df[df['label']==1]\n",
    "neg = df[df['label']==0]\n",
    "neg_len = len(neg)\n",
    "pos = pos.sample(n = neg_len, replace = False)\n",
    "df2 = pd.concat([pos, neg])\n",
    "df2 = df2.sample(frac=1)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.to_csv('data/solvability_balanced.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d108a0ba-ea55-4b81-9409-1e4827331162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files=\"data/solvability_balanced.csv\")\n",
    "#dataset = load_dataset('csv', data_files=\"balanced.csv\")\n",
    "\n",
    "# Get the total number of examples in the dataset\n",
    "# total_examples = len(dataset['train'])\n",
    "\n",
    "# # Calculate the sizes of the training, test, and validation sets\n",
    "# train_size = int(0.8 * total_examples)\n",
    "# test_size = int(0.1 * total_examples)\n",
    "# valid_size = total_examples - train_size - test_size\n",
    "\n",
    "# # Manually split the dataset into training, test, and validation sets\n",
    "# train_dataset = dataset['train'].shuffle(seed=42).select(range(train_size))\n",
    "# test_dataset = dataset['train'].shuffle(seed=42).select(range(train_size, train_size + test_size))\n",
    "# valid_dataset = dataset['train'].shuffle(seed=42).select(range(train_size + test_size, total_examples))\n",
    "\n",
    "dataset_train_valid_test = dataset['train'].train_test_split(test_size = .2, seed = 42)\n",
    "dataset_valid_test = dataset_train_valid_test['test'].train_test_split(test_size = .5, seed = 42)\n",
    "# Create a DatasetDict to hold the splits\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': dataset_train_valid_test['train'],\n",
    "    'test': dataset_valid_test['train'],\n",
    "    'valid': dataset_valid_test['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f43d5947-9ac6-4f4b-9fff-004105e4dfde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99b8776edc343fa980c7a66374e4f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set up tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=True)\n",
    "# tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "\n",
    "#Preprocess and collate data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train_test_valid_dataset = train_test_valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "44073996-4615-4e90-9a1d-ee7b4ffde147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "#Prepare evaluation function\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# roc_auc = evaluate.load(\"roc_auc\")\n",
    "\n",
    "# import numpy as np\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     return roc_auc.compute(prediction_scores=predictions, references=labels)\n",
    "\n",
    "#Training\n",
    "id2label = {0: \"NOT SOLVABLE\", 1: \"SOLVABLE\"}\n",
    "label2id = {\"NOT SOLVABLE\": 0, \"SOLVABLE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0b4deda2-88a0-4e89-902f-c776e1c50a76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Import model\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"meta-llama/Llama-2-7b-hf\", num_labels=2, id2label=id2label, label2id=label2id,\n",
    "#         use_auth_token=True,  \n",
    "#       # max_memory=max_memory,\n",
    "#       # torch_dtype=torch.bfloat16, \n",
    "#       device_map = 'auto',\n",
    "#         quantization_config=BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type='nf4'))\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id,\n",
    "#         use_auth_token=True,  \n",
    "#       # max_memory=max_memory,\n",
    "#       # torch_dtype=torch.bfloat16, \n",
    "#         quantization_config=BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type='nf4'))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "14b98067-f979-4d72-bb6a-cc94e288829c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='153' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [153/184 00:52 < 00:10, 2.86 it/s, Epoch 6.61/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.710070</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.745079</td>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709998</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708976</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702449</td>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722045</td>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#trainer.train(resume_from_checkpoint=True)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenized_train_test_valid_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     26\u001b[0m test_input_data \u001b[38;5;241m=\u001b[39m tokenized_train_test_valid_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1814\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"solvability_classifier\",\n",
    "    learning_rate=.0001,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_test_valid_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_train_test_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()\n",
    "print(tokenized_train_test_valid_dataset[\"test\"])\n",
    "test_input_data = tokenized_train_test_valid_dataset[\"test\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae7ba5a1-c05d-4a8f-aae0-18287aa6b2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4754084646701813,\n",
       " 'eval_accuracy': 0.8242424242424242,\n",
       " 'eval_runtime': 1.6531,\n",
       " 'eval_samples_per_second': 99.81,\n",
       " 'eval_steps_per_second': 6.654,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions = trainer.predict(test_dataset=test_input_data)\n",
    "# print(predictions)\n",
    "trainer.evaluate(eval_dataset = tokenized_train_test_valid_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50dab008-6784-4365-80ba-e06046419a62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-1.1767561 ,  0.85649323],\n",
       "       [-1.0614527 ,  0.8524137 ],\n",
       "       [-1.1524765 ,  0.9674901 ],\n",
       "       [-1.169087  ,  0.85458505],\n",
       "       [-1.118228  ,  0.9000377 ],\n",
       "       [-1.0491871 ,  0.88732153],\n",
       "       [-1.0239848 ,  0.929475  ],\n",
       "       [-1.1332685 ,  0.91266596],\n",
       "       [-1.0671339 ,  0.9459554 ],\n",
       "       [-1.1351367 ,  0.8960755 ],\n",
       "       [-1.1527706 ,  0.86005044],\n",
       "       [-1.0023655 ,  0.8505782 ],\n",
       "       [-1.1405097 ,  0.8213093 ],\n",
       "       [-1.0786202 ,  0.8799991 ],\n",
       "       [-1.1250837 ,  0.88174665],\n",
       "       [-1.02384   ,  0.8139355 ],\n",
       "       [-1.1747395 ,  0.82902414],\n",
       "       [-1.1255609 ,  0.92080224],\n",
       "       [-0.90249366,  1.0001096 ],\n",
       "       [-1.0512965 ,  0.8697106 ],\n",
       "       [-1.0555145 ,  0.945542  ],\n",
       "       [-1.0722532 ,  0.88484186],\n",
       "       [-1.1100919 ,  0.9010052 ],\n",
       "       [-1.0702143 ,  0.9194692 ],\n",
       "       [-1.1220598 ,  0.8647202 ],\n",
       "       [-1.088548  ,  0.9485705 ],\n",
       "       [-1.1189343 ,  0.8919009 ],\n",
       "       [-1.2064078 ,  0.7924659 ],\n",
       "       [-1.0510939 ,  0.8529482 ],\n",
       "       [-1.1073792 ,  0.9245366 ],\n",
       "       [-1.1010901 ,  0.86948943],\n",
       "       [-1.1096803 ,  0.8577429 ],\n",
       "       [-1.1513033 ,  0.9165291 ],\n",
       "       [-1.133054  ,  0.9408214 ],\n",
       "       [-1.097172  ,  0.8810878 ],\n",
       "       [-1.0032406 ,  0.99607855],\n",
       "       [-1.1074741 ,  0.8328041 ],\n",
       "       [-1.1746832 ,  0.81732297],\n",
       "       [-1.1156696 ,  0.9214476 ],\n",
       "       [-1.027515  ,  0.8704246 ],\n",
       "       [-1.1810949 ,  0.8944483 ],\n",
       "       [-1.0800738 ,  0.90661424],\n",
       "       [-1.0696009 ,  0.88808066],\n",
       "       [-1.0839444 ,  0.8973872 ],\n",
       "       [-1.2195084 ,  0.8739666 ],\n",
       "       [-1.1035358 ,  0.81771934],\n",
       "       [-0.94646436,  1.0045457 ],\n",
       "       [-1.0725025 ,  0.8357908 ],\n",
       "       [-1.1518872 ,  0.82305425],\n",
       "       [-1.1927165 ,  0.9113939 ],\n",
       "       [-1.1208181 ,  0.79031444],\n",
       "       [-1.205218  ,  0.91817063],\n",
       "       [-1.1524702 ,  0.85689557],\n",
       "       [-1.0518497 ,  0.9397902 ],\n",
       "       [-1.1114771 ,  0.95788866],\n",
       "       [-1.0576727 ,  0.8909869 ],\n",
       "       [-0.8978936 ,  0.8735994 ],\n",
       "       [-1.1650841 ,  0.8125494 ],\n",
       "       [-1.114086  ,  0.8998607 ],\n",
       "       [-1.1086382 ,  0.88268435],\n",
       "       [-1.1423528 ,  0.87742436],\n",
       "       [-1.0363262 ,  0.9499328 ],\n",
       "       [-1.0006756 ,  0.87070876],\n",
       "       [-1.0256594 ,  1.0334048 ],\n",
       "       [-1.0846213 ,  0.95282483],\n",
       "       [-0.99260736,  0.8225792 ],\n",
       "       [-1.1128465 ,  0.83940506],\n",
       "       [-1.0663413 ,  0.9686655 ],\n",
       "       [-1.1787069 ,  0.8332471 ],\n",
       "       [-1.0091864 ,  0.86445487],\n",
       "       [-1.094236  ,  0.81927234],\n",
       "       [-1.1710131 ,  0.930954  ],\n",
       "       [-1.1533114 ,  0.7858803 ],\n",
       "       [-0.9402375 ,  0.9166479 ],\n",
       "       [-1.1311911 ,  0.86581826],\n",
       "       [-1.071487  ,  0.90272367],\n",
       "       [-1.160052  ,  0.9174985 ],\n",
       "       [-1.0211976 ,  0.88373154],\n",
       "       [-1.1126214 ,  0.91935277],\n",
       "       [-0.97628915,  0.8416599 ],\n",
       "       [-1.0954924 ,  0.9015168 ],\n",
       "       [-1.0440456 ,  0.87618995],\n",
       "       [-0.92187136,  0.9159519 ],\n",
       "       [-1.0613931 ,  0.95230013],\n",
       "       [-0.9229673 ,  1.006084  ],\n",
       "       [-1.0952754 ,  0.89607286],\n",
       "       [-1.1191179 ,  0.91909164],\n",
       "       [-1.0234356 ,  0.95392084],\n",
       "       [-1.0794507 ,  0.8584317 ],\n",
       "       [-1.0536532 ,  0.93032163],\n",
       "       [-1.0515658 ,  0.8660491 ],\n",
       "       [-1.1761346 ,  0.8963512 ],\n",
       "       [-1.0207574 ,  0.94598335],\n",
       "       [-1.1075597 ,  0.88968575],\n",
       "       [-1.1803843 ,  0.86533916],\n",
       "       [-0.9971376 ,  0.97532076],\n",
       "       [-1.1495411 ,  0.8853924 ],\n",
       "       [-1.1054174 ,  0.9049605 ],\n",
       "       [-1.1128942 ,  0.8065448 ],\n",
       "       [-1.0490187 ,  0.92159677],\n",
       "       [-1.115154  ,  0.85848224],\n",
       "       [-1.0510308 ,  0.88847756],\n",
       "       [-1.1527323 ,  0.88891214],\n",
       "       [-1.1014742 ,  0.8202352 ],\n",
       "       [-1.0561628 ,  0.9729046 ],\n",
       "       [-1.0611435 ,  0.9200111 ],\n",
       "       [-1.1166058 ,  0.91870564],\n",
       "       [-1.1095183 ,  0.8249751 ],\n",
       "       [-1.0335665 ,  0.90143436],\n",
       "       [-1.2157878 ,  0.9050602 ],\n",
       "       [-1.0367317 ,  0.865789  ],\n",
       "       [-0.97797036,  0.9003664 ],\n",
       "       [-1.1100204 ,  0.9381539 ],\n",
       "       [-1.1030761 ,  0.8000858 ],\n",
       "       [-1.0966663 ,  0.9393289 ],\n",
       "       [-1.0361564 ,  0.9139128 ],\n",
       "       [-1.1565483 ,  0.88039404],\n",
       "       [-1.0075761 ,  0.92840236],\n",
       "       [-1.1772431 ,  0.9533495 ],\n",
       "       [-0.9970331 ,  0.9429222 ],\n",
       "       [-1.0844616 ,  0.8636832 ],\n",
       "       [-1.049821  ,  0.8592862 ],\n",
       "       [-1.0694838 ,  0.88489866],\n",
       "       [-1.0666779 ,  0.8880944 ],\n",
       "       [-1.1157126 ,  0.8715451 ],\n",
       "       [-1.1059616 ,  0.91923   ],\n",
       "       [-1.1269578 ,  0.8267813 ],\n",
       "       [-1.0968336 ,  0.86806405],\n",
       "       [-1.1043203 ,  0.81915295],\n",
       "       [-1.144344  ,  0.80330324],\n",
       "       [-1.1146691 ,  0.8617394 ],\n",
       "       [-1.096084  ,  0.83284634],\n",
       "       [-1.1245338 ,  0.95950174],\n",
       "       [-1.0581919 ,  0.8920168 ],\n",
       "       [-1.0617288 ,  0.8635428 ],\n",
       "       [-1.0803739 ,  0.8432634 ],\n",
       "       [-1.1354303 ,  0.8305183 ],\n",
       "       [-1.1194751 ,  0.8360977 ],\n",
       "       [-0.9745324 ,  0.9217549 ],\n",
       "       [-1.0264521 ,  0.8812328 ],\n",
       "       [-1.1313913 ,  0.8826379 ],\n",
       "       [-1.1185788 ,  0.9063659 ],\n",
       "       [-1.1191652 ,  0.88192487],\n",
       "       [-1.0945045 ,  0.8784237 ],\n",
       "       [-1.1075858 ,  0.88656354],\n",
       "       [-1.0590489 ,  0.91289777],\n",
       "       [-1.0515109 ,  0.91232914],\n",
       "       [-1.1663065 ,  0.9030287 ],\n",
       "       [-1.1292605 ,  0.861143  ],\n",
       "       [-1.0591711 ,  1.0188224 ],\n",
       "       [-1.1552263 ,  0.8990964 ],\n",
       "       [-1.1175171 ,  0.8871868 ],\n",
       "       [-1.0260919 ,  0.9049178 ],\n",
       "       [-1.0963484 ,  0.90301925],\n",
       "       [-1.0831147 ,  0.8795541 ],\n",
       "       [-1.153638  ,  0.8456037 ],\n",
       "       [-0.78536874,  0.7401643 ],\n",
       "       [-1.0889779 ,  0.9061037 ],\n",
       "       [-1.1033641 ,  0.8649841 ],\n",
       "       [-1.1537464 ,  0.87101126],\n",
       "       [-1.1523949 ,  0.8798848 ],\n",
       "       [-1.0522655 ,  0.8239189 ],\n",
       "       [-1.0588151 ,  0.9570337 ],\n",
       "       [-1.0415865 ,  0.9179891 ],\n",
       "       [-1.0425227 ,  0.96365345]], dtype=float32), label_ids=array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]), metrics={'test_loss': 0.4754084646701813, 'test_accuracy': 0.8242424242424242, 'test_runtime': 1.6979, 'test_samples_per_second': 97.18, 'test_steps_per_second': 6.479})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset = tokenized_train_test_valid_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126f518-58fc-4b67-b788-44901205f622",
   "metadata": {},
   "source": [
    "## Accuracy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41a783b9-bc15-4742-9844-c0a8a3f1ef4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1408</td>\n",
       "      <td>1593</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: A 250-car freight train is 3.5 miles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1449</td>\n",
       "      <td>1638</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Batman has 32 batarangs. He buys 4 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>779</td>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: The 2:00 PM train from Penn Station ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: A 15-pound cake is to be cut into 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1149</td>\n",
       "      <td>1291</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: Thor has 2000 thunderbolts. He uses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>841</td>\n",
       "      <td>948</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Captain America is in a rush to save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1027</td>\n",
       "      <td>1164</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: 100 doggos are barking at the moon. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>251</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: 1200 people were at the 1996 Olympic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1293</td>\n",
       "      <td>1454</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: A bakery made 300 muffins. 150 of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>1450</td>\n",
       "      <td>1639</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: A 5-car train is 1000 feet long. A 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0  label  \\\n",
       "0            1408        1593      1   \n",
       "1            1449        1638      1   \n",
       "2             779         879      0   \n",
       "3             570         640      0   \n",
       "4            1149        1291      1   \n",
       "..            ...         ...    ...   \n",
       "357           841         948      0   \n",
       "358          1027        1164      0   \n",
       "359           251         281      1   \n",
       "360          1293        1454      0   \n",
       "361          1450        1639      0   \n",
       "\n",
       "                                                  text  \n",
       "0    Question: A 250-car freight train is 3.5 miles...  \n",
       "1    Question: Batman has 32 batarangs. He buys 4 m...  \n",
       "2    Question: The 2:00 PM train from Penn Station ...  \n",
       "3    Question: A 15-pound cake is to be cut into 30...  \n",
       "4    Question: Thor has 2000 thunderbolts. He uses ...  \n",
       "..                                                 ...  \n",
       "357  Question: Captain America is in a rush to save...  \n",
       "358  Question: 100 doggos are barking at the moon. ...  \n",
       "359  Question: 1200 people were at the 1996 Olympic...  \n",
       "360  Question: A bakery made 300 muffins. 150 of th...  \n",
       "361  Question: A 5-car train is 1000 feet long. A 1...  \n",
       "\n",
       "[362 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/accuracy.csv')\n",
    "df['label'] = df['label'].astype('int')\n",
    "pos = df[df['label']==1]\n",
    "neg = df[df['label']==0]\n",
    "neg_len = len(neg)\n",
    "pos = pos.sample(n = neg_len, replace = False)\n",
    "df2 = pd.concat([pos, neg])\n",
    "df2 = df2.sample(frac=1)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.to_csv('data/accuracy_balanced.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d86a24c-5c08-42b9-94b3-547d77aa711e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9455948c7b6848d0b350c0757843ac06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f28b835b2bf486fb1ed40e77ff50dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb641e9b9c74905b0a269bf6ee7a61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files=\"data/accuracy.csv\")\n",
    "#dataset = load_dataset('csv', data_files=\"balanced.csv\")\n",
    "\n",
    "# Get the total number of examples in the dataset\n",
    "# total_examples = len(dataset['train'])\n",
    "\n",
    "# # Calculate the sizes of the training, test, and validation sets\n",
    "# train_size = int(0.8 * total_examples)\n",
    "# test_size = int(0.1 * total_examples)\n",
    "# valid_size = total_examples - train_size - test_size\n",
    "\n",
    "# # Manually split the dataset into training, test, and validation sets\n",
    "# train_dataset = dataset['train'].shuffle(seed=42).select(range(train_size))\n",
    "# test_dataset = dataset['train'].shuffle(seed=42).select(range(train_size, train_size + test_size))\n",
    "# valid_dataset = dataset['train'].shuffle(seed=42).select(range(train_size + test_size, total_examples))\n",
    "\n",
    "dataset_train_valid_test = dataset['train'].train_test_split(test_size = .2, seed = 42)\n",
    "dataset_valid_test = dataset_train_valid_test['test'].train_test_split(test_size = .5, seed = 42)\n",
    "# Create a DatasetDict to hold the splits\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': dataset_train_valid_test['train'],\n",
    "    'test': dataset_valid_test['train'],\n",
    "    'valid': dataset_valid_test['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a3bf617-3b65-4c98-8de2-116778cced5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636e3028c7284cd8a1e0e8a594f29f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c410960ff554d34ad6a3b12f775ad31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2e425c1aba4a6facdd03921c120537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set up tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=True)\n",
    "# tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#tokenizer.add_special_tokens({\"pad_token\":\"[PAD]\"})\n",
    "\n",
    "#Preprocess and collate data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train_test_valid_dataset = train_test_valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08274402-c9aa-4d59-aef5-41d2929c4b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "#Prepare evaluation function\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# roc_auc = evaluate.load(\"roc_auc\")\n",
    "\n",
    "# import numpy as np\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "#     return roc_auc.compute(prediction_scores=predictions, references=labels)\n",
    "\n",
    "#Training\n",
    "id2label = {0: \"NOT ACCURATE\", 1: \"ACCURATE\"}\n",
    "label2id = {\"NOT ACCURATE\": 0, \"ACCURATE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2f52d81-6c92-4b49-a2bb-2d139bd9f173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Import model\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"meta-llama/Llama-2-7b-hf\", num_labels=2, id2label=id2label, label2id=label2id,\n",
    "#         use_auth_token=True,  \n",
    "#       # max_memory=max_memory,\n",
    "#       # torch_dtype=torch.bfloat16, \n",
    "#       device_map = 'auto',\n",
    "#         quantization_config=BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type='nf4'))\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id,\n",
    "#         use_auth_token=True,  \n",
    "#       # max_memory=max_memory,\n",
    "#       # torch_dtype=torch.bfloat16, \n",
    "#         quantization_config=BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type='nf4'))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f28ff20e-dee4-4e1d-aa82-4adebed21aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "num_ftrs = model.classifier.in_features\n",
    "num_classes = 2\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 2048),\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),         # Activation function (you can choose other activation functions too)\n",
    "    nn.Dropout(0.4),               # Dropout layer with 20% probability\n",
    "    nn.Linear(2048, num_classes)    # Final prediction fc layer\n",
    ")\n",
    "\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a535fba-893c-43da-8b76-11dc75e84480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='304' max='304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [304/304 02:09, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668812</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697771</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.666479</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695753</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.683936</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680576</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.674869</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.671905</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.674588</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.674450</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.679161</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678825</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.679823</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.679931</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681584</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 36\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"accuracy_classifier\",\n",
    "    learning_rate=.0001,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=16,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_test_valid_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_train_test_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()\n",
    "print(tokenized_train_test_valid_dataset[\"test\"])\n",
    "test_input_data = tokenized_train_test_valid_dataset[\"test\"][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6519a4f-760f-4652-bbf9-c68ac134a223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6006247997283936,\n",
       " 'eval_accuracy': 0.7222222222222222,\n",
       " 'eval_runtime': 0.3929,\n",
       " 'eval_samples_per_second': 91.624,\n",
       " 'eval_steps_per_second': 7.635,\n",
       " 'epoch': 16.0}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions = trainer.predict(test_dataset=test_input_data)\n",
    "# print(predictions)\n",
    "trainer.evaluate(eval_dataset = tokenized_train_test_valid_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f7e8e6e-d2fb-4cc4-a877-fe87ca3a21a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.18069279, -0.3302801 ],\n",
       "       [-0.9518123 ,  0.47074184],\n",
       "       [-0.01721567, -0.4875356 ],\n",
       "       [ 0.03432662, -0.54198587],\n",
       "       [-0.16459821, -0.34577116],\n",
       "       [-0.63464725,  0.15332495],\n",
       "       [-0.48832142, -0.05141906],\n",
       "       [-0.09577274, -0.40060315],\n",
       "       [ 0.06358947, -0.5704366 ],\n",
       "       [-0.00658918, -0.5122216 ],\n",
       "       [-0.8930766 ,  0.4183537 ],\n",
       "       [ 0.03362607, -0.5435797 ],\n",
       "       [ 0.09024355, -0.6205659 ],\n",
       "       [-0.53265965,  0.02194048],\n",
       "       [-0.30711085, -0.22469023],\n",
       "       [-0.0957941 , -0.38266465],\n",
       "       [-0.16097395, -0.34766385],\n",
       "       [ 0.09210249, -0.62115765],\n",
       "       [-0.40707126, -0.10799819],\n",
       "       [-0.1552012 , -0.35554382],\n",
       "       [-0.5531868 ,  0.02562427],\n",
       "       [-0.82378936,  0.34623808],\n",
       "       [-0.52354175, -0.03060995],\n",
       "       [ 0.39264107, -0.89842   ],\n",
       "       [-0.67864734,  0.16242935],\n",
       "       [-0.5714083 ,  0.04729527],\n",
       "       [-0.73194873,  0.22674198],\n",
       "       [ 0.374745  , -0.8789548 ],\n",
       "       [-0.82494515,  0.33106148],\n",
       "       [-0.4630864 , -0.0508122 ],\n",
       "       [ 0.46987605, -0.9726257 ],\n",
       "       [-0.44473404, -0.06108946],\n",
       "       [ 0.36575282, -0.8719757 ],\n",
       "       [-0.47271305, -0.05405291],\n",
       "       [-0.4573338 , -0.08922992],\n",
       "       [ 0.59378135, -1.0694278 ]], dtype=float32), label_ids=array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0]), metrics={'test_loss': 0.6006247997283936, 'test_accuracy': 0.7222222222222222, 'test_runtime': 0.4455, 'test_samples_per_second': 80.815, 'test_steps_per_second': 6.735})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset = tokenized_train_test_valid_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d5663-07de-4e0a-be2d-3e08f25dd866",
   "metadata": {},
   "source": [
    "# Testing on IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3377afa-26bb-4be5-96ee-00969879a288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bf2caf-f0b9-468f-970b-3d8a50751958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"/home/sagemaker-user/bitsandbytes\")\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023e2b34-54b4-45d1-8028-f357e869b9be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='351' max='6252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 351/6252 23:41 < 6:40:27, 0.25 it/s, Epoch 0.22/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302497</td>\n",
       "      <td>0.876960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250724</td>\n",
       "      <td>0.900440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263815</td>\n",
       "      <td>0.904360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m\n\u001b[1;32m      5\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      6\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2665\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2665\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:1853\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1853\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"text_classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",  # Change evaluation strategy to \"steps\"\n",
    "    eval_steps=100,  # Set the evaluation frequency to every 100 steps\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb['train'],\n",
    "    eval_dataset=tokenized_imdb['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43b6f34-f549-4510-a53d-0f6ca7b258b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudatoolkit               11.8.0              h4ba93d1_12    conda-forge\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list | grep cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d635108-9a58-4bda-a224-26e69920ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0ec1e-b9e9-498f-ac6d-8b89466585b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
